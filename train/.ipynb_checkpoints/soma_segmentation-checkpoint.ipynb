{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16102fd",
   "metadata": {},
   "source": [
    "# Steps for training detectron2 on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edff8f4",
   "metadata": {},
   "source": [
    "### Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480f0a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "\n",
    "os.chdir(\"C:/Users/admin/Documents/Python Scripts/Soma-Segmentation/train\")\n",
    "from utils import ImageJ2COCO\n",
    "from config import configuration\n",
    "from segmentation_predictor import predict_img\n",
    "\n",
    "\n",
    "#from train import run_train\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import DatasetMapper   # the default mapper\n",
    "from detectron2.data import build_detection_train_loader\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cdd81",
   "metadata": {},
   "source": [
    "### Registering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd46383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data already is in COCO style\n",
    "register_coco_instances(\"train\", {}, \"I:/Sina/Medical report segmentation/publaynet/val.json\", \n",
    "                        \"I:/Sina/Medical report segmentation/publaynet/val\")\n",
    "register_coco_instances(\"val\", {}, \"I:/Sina/Medical report segmentation/publaynet/val.json\", \n",
    "                        \"I:/Sina/Medical report segmentation/publaynet/val\")\n",
    "\n",
    "\n",
    "#MetadataCatalog.get(\"val\").set(thing_classes=[\"title\", \"text\", \"figure\", \"table\", \"list\"])\n",
    "#MetadataCatalog.get(\"train\").set(thing_classes=[\"title\", \"text\", \"figure\", \"table\", \"list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d9100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for custom data with custom written dataloader\n",
    "\n",
    "# dataloader for train dataset (this custom written data loader is able to load multple datasets from different location)\n",
    "img2coco_train = ImageJ2COCO(image_path=[\"G:/Data & Analysis/150802_p3.5_gcamp6/Data/150802_p3.5_gcamp6 H5/150802_a3_1h40min.h5\",\n",
    "                                   \"G:/Data & Analysis/150802_p3.5_gcamp6/Data/150802_p3.5_gcamp6 H5/150802_a3_1h40min.h5\"], \n",
    "                           label_path=[\"G:/Data & Analysis/150802_p3.5_gcamp6/Analysis/ROIS and Inside Activities/RoiSetFull.zip\", \n",
    "                                       \"G:/Data & Analysis/150802_p3.5_gcamp6/Analysis/ROIS and Inside Activities/RoiSetFull.zip\"], \n",
    "                           output_path=\"C:/Users/admin/Desktop/test\", \n",
    "                           start_index=[10000, 12000], \n",
    "                           end_index=[12000, 14000], \n",
    "                           image_nr=[1400, 1500], \n",
    "                           id_starter=[1, 2000], \n",
    "                           min_intensity = [100, 100], \n",
    "                           max_intensity = [4000, 3000], \n",
    "                           image_scale = [(128,128), (128,128)], \n",
    "                           image_rotation = [-90, -90],\n",
    "                           key = [\"GroupHierarchy.Groups.Datasets\", \n",
    "                                  \"GroupHierarchy.Groups.Datasets\"])\n",
    "\n",
    "# dataloader for validation dataset (this custom written data loader is able to load multple datasets from different location)\n",
    "img2coco_val = ImageJ2COCO(image_path=[\"G:/Data & Analysis/150802_p3.5_gcamp6/Data/150802_p3.5_gcamp6 H5/150802_a3_1h40min.h5\",\n",
    "                                   \"G:/Data & Analysis/150802_p3.5_gcamp6/Data/150802_p3.5_gcamp6 H5/150802_a3_1h40min.h5\"], \n",
    "                           label_path=[\"G:/Data & Analysis/150802_p3.5_gcamp6/Analysis/ROIS and Inside Activities/RoiSetFull.zip\", \n",
    "                                       \"G:/Data & Analysis/150802_p3.5_gcamp6/Analysis/ROIS and Inside Activities/RoiSetFull.zip\"], \n",
    "                           output_path=\"C:/Users/admin/Desktop/test\", \n",
    "                           start_index=[1000, 1200], \n",
    "                           end_index=[20000, 40000], \n",
    "                           image_nr=[800, 800], \n",
    "                           id_starter=[3000, 4000], \n",
    "                           min_intensity = [100, 100], \n",
    "                           max_intensity = [4000, 3000], \n",
    "                           image_scale = [(128,128), (128,128)], \n",
    "                           image_rotation = [-90, -90],\n",
    "                           key = [\"GroupHierarchy.Groups.Datasets\", \n",
    "                                  \"GroupHierarchy.Groups.Datasets\"])\n",
    "\n",
    "# register train data set\n",
    "DatasetCatalog.register(\"train\", img2coco_train.transform)\n",
    "MetadataCatalog.get(\"train\").set(thing_classes=[\"soma\"]) # define classes as well\n",
    "\n",
    "# register validation data set\n",
    "DatasetCatalog.register(\"val\", img2coco_val.transform)\n",
    "MetadataCatalog.get(\"val\").set(thing_classes=[\"soma\"]) # define classes as well\n",
    "\n",
    "metadata = MetadataCatalog.get(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fdf4d",
   "metadata": {},
   "source": [
    "### Check visually the data load step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9cfc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1400/1400 [00:03<00:00, 434.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4002/4002 [00:14<00:00, 285.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1500/1500 [00:02<00:00, 566.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4002/4002 [00:18<00:00, 213.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "\n",
    "mydata = DatasetCatalog.get(\"train\")\n",
    "mydata_metdata = MetadataCatalog.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ee8f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "%matplotlib inline\n",
    "\n",
    "for d in random.sample(mydata, 1):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=mydata_metdata, \n",
    "                   scale=1, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_dataset_dict(d)\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb72f6",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f81493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration file\n",
    "cfg = configuration(num_classes=5,\n",
    "                    train_output_path=\"C:/Users/admin/Desktop/test/out2\",\n",
    "                    min_image_size=125,\n",
    "                    image_per_batch=1,\n",
    "                    max_iter=1500, \n",
    "                    base_lr = 0.001,\n",
    "                    model_weights=False, #\"C:/Users/admin/Desktop/test/out/model_final.pth\", # if you have another weights give that one\n",
    "                    validation=True) # if you have validation turn it to True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd376cf",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06050f",
   "metadata": {},
   "source": [
    "#### Default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77873772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:44:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1400/1400 [00:03<00:00, 448.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4003/4003 [00:12<00:00, 329.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1500/1500 [00:03<00:00, 491.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4003/4003 [00:14<00:00, 269.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:45:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 8000 images left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:45:10 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    soma    | 80000        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/12 16:45:10 d2.data.common]: \u001b[0mSerializing 8000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 16:45:11 d2.data.common]: \u001b[0mSerialized dataset takes 33.11 MiB\n",
      "\u001b[32m[10/12 16:45:11 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(125,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/12 16:45:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:45:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\detectron2-windows\\detectron2\\layers\\wrappers.py:226: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  return x.nonzero().unbind(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:45:26 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 19  total_loss: 4.601  loss_cls: 0.703  loss_box_reg: 0.286  loss_mask: 0.685  loss_rpn_cls: 2.677  loss_rpn_loc: 0.375  time: 0.2677  data_time: 0.3076  lr: 0.000020  max_mem: 850M\n",
      "\u001b[32m[10/12 16:45:31 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 39  total_loss: 2.534  loss_cls: 0.456  loss_box_reg: 0.504  loss_mask: 0.677  loss_rpn_cls: 0.626  loss_rpn_loc: 0.258  time: 0.2698  data_time: 0.0036  lr: 0.000040  max_mem: 875M\n",
      "\u001b[32m[10/12 16:45:37 d2.utils.events]: \u001b[0m eta: 1:07:24  iter: 59  total_loss: 1.949  loss_cls: 0.349  loss_box_reg: 0.366  loss_mask: 0.659  loss_rpn_cls: 0.300  loss_rpn_loc: 0.224  time: 0.2702  data_time: 0.0032  lr: 0.000060  max_mem: 875M\n",
      "\u001b[32m[10/12 16:45:43 d2.utils.events]: \u001b[0m eta: 1:07:23  iter: 79  total_loss: 1.846  loss_cls: 0.352  loss_box_reg: 0.394  loss_mask: 0.644  loss_rpn_cls: 0.215  loss_rpn_loc: 0.191  time: 0.2707  data_time: 0.0039  lr: 0.000080  max_mem: 875M\n",
      "\u001b[32m[10/12 16:45:48 d2.utils.events]: \u001b[0m eta: 1:07:53  iter: 99  total_loss: 1.846  loss_cls: 0.378  loss_box_reg: 0.482  loss_mask: 0.627  loss_rpn_cls: 0.170  loss_rpn_loc: 0.166  time: 0.2716  data_time: 0.0031  lr: 0.000100  max_mem: 906M\n",
      "\u001b[32m[10/12 16:45:54 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 119  total_loss: 1.842  loss_cls: 0.389  loss_box_reg: 0.566  loss_mask: 0.608  loss_rpn_cls: 0.160  loss_rpn_loc: 0.147  time: 0.2722  data_time: 0.0025  lr: 0.000120  max_mem: 947M\n",
      "\u001b[32m[10/12 16:45:59 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 139  total_loss: 1.801  loss_cls: 0.382  loss_box_reg: 0.586  loss_mask: 0.595  loss_rpn_cls: 0.120  loss_rpn_loc: 0.123  time: 0.2737  data_time: 0.0032  lr: 0.000140  max_mem: 987M\n",
      "\u001b[32m[10/12 16:46:05 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 159  total_loss: 1.806  loss_cls: 0.376  loss_box_reg: 0.642  loss_mask: 0.579  loss_rpn_cls: 0.116  loss_rpn_loc: 0.108  time: 0.2751  data_time: 0.0021  lr: 0.000160  max_mem: 1004M\n",
      "\u001b[32m[10/12 16:46:11 d2.utils.events]: \u001b[0m eta: 1:08:17  iter: 179  total_loss: 1.760  loss_cls: 0.364  loss_box_reg: 0.661  loss_mask: 0.557  loss_rpn_cls: 0.097  loss_rpn_loc: 0.101  time: 0.2764  data_time: 0.0031  lr: 0.000180  max_mem: 1015M\n",
      "\u001b[32m[10/12 16:46:17 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 199  total_loss: 1.717  loss_cls: 0.340  loss_box_reg: 0.680  loss_mask: 0.540  loss_rpn_cls: 0.081  loss_rpn_loc: 0.094  time: 0.2774  data_time: 0.0017  lr: 0.000200  max_mem: 1047M\n",
      "\u001b[32m[10/12 16:46:23 d2.utils.events]: \u001b[0m eta: 1:08:34  iter: 219  total_loss: 1.637  loss_cls: 0.319  loss_box_reg: 0.678  loss_mask: 0.503  loss_rpn_cls: 0.059  loss_rpn_loc: 0.085  time: 0.2787  data_time: 0.0031  lr: 0.000220  max_mem: 1047M\n",
      "\u001b[32m[10/12 16:46:29 d2.utils.events]: \u001b[0m eta: 1:08:45  iter: 239  total_loss: 1.537  loss_cls: 0.289  loss_box_reg: 0.638  loss_mask: 0.472  loss_rpn_cls: 0.052  loss_rpn_loc: 0.081  time: 0.2799  data_time: 0.0035  lr: 0.000240  max_mem: 1063M\n",
      "\u001b[32m[10/12 16:46:34 d2.utils.events]: \u001b[0m eta: 1:08:39  iter: 259  total_loss: 1.536  loss_cls: 0.277  loss_box_reg: 0.421  loss_mask: 0.493  loss_rpn_cls: 0.098  loss_rpn_loc: 0.191  time: 0.2799  data_time: 0.0029  lr: 0.000260  max_mem: 1063M\n",
      "\u001b[32m[10/12 16:46:40 d2.utils.events]: \u001b[0m eta: 1:08:57  iter: 279  total_loss: 1.499  loss_cls: 0.287  loss_box_reg: 0.628  loss_mask: 0.449  loss_rpn_cls: 0.059  loss_rpn_loc: 0.101  time: 0.2810  data_time: 0.0048  lr: 0.000280  max_mem: 1063M\n",
      "\u001b[32m[10/12 16:46:46 d2.utils.events]: \u001b[0m eta: 1:09:13  iter: 299  total_loss: 1.397  loss_cls: 0.251  loss_box_reg: 0.639  loss_mask: 0.415  loss_rpn_cls: 0.038  loss_rpn_loc: 0.092  time: 0.2818  data_time: 0.0026  lr: 0.000300  max_mem: 1063M\n",
      "\u001b[32m[10/12 16:46:52 d2.utils.events]: \u001b[0m eta: 1:09:23  iter: 319  total_loss: 1.235  loss_cls: 0.234  loss_box_reg: 0.532  loss_mask: 0.375  loss_rpn_cls: 0.045  loss_rpn_loc: 0.087  time: 0.2827  data_time: 0.0039  lr: 0.000320  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:46:58 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 339  total_loss: 1.177  loss_cls: 0.213  loss_box_reg: 0.512  loss_mask: 0.328  loss_rpn_cls: 0.031  loss_rpn_loc: 0.084  time: 0.2835  data_time: 0.0041  lr: 0.000340  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:04 d2.utils.events]: \u001b[0m eta: 1:09:32  iter: 359  total_loss: 1.120  loss_cls: 0.231  loss_box_reg: 0.449  loss_mask: 0.308  loss_rpn_cls: 0.024  loss_rpn_loc: 0.077  time: 0.2842  data_time: 0.0037  lr: 0.000360  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:10 d2.utils.events]: \u001b[0m eta: 1:09:36  iter: 379  total_loss: 1.127  loss_cls: 0.205  loss_box_reg: 0.361  loss_mask: 0.328  loss_rpn_cls: 0.089  loss_rpn_loc: 0.104  time: 0.2847  data_time: 0.0046  lr: 0.000380  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:16 d2.utils.events]: \u001b[0m eta: 1:09:39  iter: 399  total_loss: 1.017  loss_cls: 0.186  loss_box_reg: 0.357  loss_mask: 0.304  loss_rpn_cls: 0.047  loss_rpn_loc: 0.072  time: 0.2853  data_time: 0.0037  lr: 0.000400  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:22 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 419  total_loss: 0.939  loss_cls: 0.168  loss_box_reg: 0.321  loss_mask: 0.281  loss_rpn_cls: 0.031  loss_rpn_loc: 0.081  time: 0.2856  data_time: 0.0029  lr: 0.000420  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:28 d2.utils.events]: \u001b[0m eta: 1:10:01  iter: 439  total_loss: 0.729  loss_cls: 0.152  loss_box_reg: 0.283  loss_mask: 0.237  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 0.2863  data_time: 0.0037  lr: 0.000440  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:34 d2.utils.events]: \u001b[0m eta: 1:10:03  iter: 459  total_loss: 0.688  loss_cls: 0.147  loss_box_reg: 0.248  loss_mask: 0.216  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 0.2869  data_time: 0.0041  lr: 0.000460  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:40 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 479  total_loss: 0.654  loss_cls: 0.139  loss_box_reg: 0.217  loss_mask: 0.211  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 0.2873  data_time: 0.0035  lr: 0.000480  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:46 d2.utils.events]: \u001b[0m eta: 1:10:17  iter: 499  total_loss: 0.626  loss_cls: 0.133  loss_box_reg: 0.225  loss_mask: 0.198  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 0.2877  data_time: 0.0040  lr: 0.000500  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:52 d2.utils.events]: \u001b[0m eta: 1:10:20  iter: 519  total_loss: 0.545  loss_cls: 0.121  loss_box_reg: 0.200  loss_mask: 0.180  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 0.2883  data_time: 0.0037  lr: 0.000519  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:47:58 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 539  total_loss: 0.514  loss_cls: 0.114  loss_box_reg: 0.171  loss_mask: 0.164  loss_rpn_cls: 0.008  loss_rpn_loc: 0.064  time: 0.2886  data_time: 0.0023  lr: 0.000539  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:04 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 559  total_loss: 0.583  loss_cls: 0.112  loss_box_reg: 0.183  loss_mask: 0.162  loss_rpn_cls: 0.017  loss_rpn_loc: 0.102  time: 0.2887  data_time: 0.0037  lr: 0.000559  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:10 d2.utils.events]: \u001b[0m eta: 1:10:20  iter: 579  total_loss: 0.575  loss_cls: 0.111  loss_box_reg: 0.191  loss_mask: 0.152  loss_rpn_cls: 0.009  loss_rpn_loc: 0.095  time: 0.2890  data_time: 0.0022  lr: 0.000579  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:16 d2.utils.events]: \u001b[0m eta: 1:10:18  iter: 599  total_loss: 0.527  loss_cls: 0.108  loss_box_reg: 0.194  loss_mask: 0.158  loss_rpn_cls: 0.013  loss_rpn_loc: 0.070  time: 0.2892  data_time: 0.0027  lr: 0.000599  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:22 d2.utils.events]: \u001b[0m eta: 1:10:19  iter: 619  total_loss: 0.508  loss_cls: 0.105  loss_box_reg: 0.188  loss_mask: 0.153  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 0.2894  data_time: 0.0024  lr: 0.000619  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:27 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 639  total_loss: 0.469  loss_cls: 0.089  loss_box_reg: 0.160  loss_mask: 0.151  loss_rpn_cls: 0.016  loss_rpn_loc: 0.062  time: 0.2894  data_time: 0.0023  lr: 0.000639  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:33 d2.utils.events]: \u001b[0m eta: 1:10:16  iter: 659  total_loss: 0.468  loss_cls: 0.093  loss_box_reg: 0.154  loss_mask: 0.144  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 0.2895  data_time: 0.0042  lr: 0.000659  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:39 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 679  total_loss: 0.530  loss_cls: 0.085  loss_box_reg: 0.151  loss_mask: 0.132  loss_rpn_cls: 0.012  loss_rpn_loc: 0.097  time: 0.2896  data_time: 0.0039  lr: 0.000679  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:48:45 d2.utils.events]: \u001b[0m eta: 1:10:08  iter: 699  total_loss: 0.477  loss_cls: 0.084  loss_box_reg: 0.162  loss_mask: 0.126  loss_rpn_cls: 0.014  loss_rpn_loc: 0.085  time: 0.2898  data_time: 0.0030  lr: 0.000699  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:51 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 719  total_loss: 0.433  loss_cls: 0.083  loss_box_reg: 0.141  loss_mask: 0.116  loss_rpn_cls: 0.012  loss_rpn_loc: 0.085  time: 0.2901  data_time: 0.0021  lr: 0.000719  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:48:57 d2.utils.events]: \u001b[0m eta: 1:10:06  iter: 739  total_loss: 0.397  loss_cls: 0.075  loss_box_reg: 0.135  loss_mask: 0.113  loss_rpn_cls: 0.008  loss_rpn_loc: 0.062  time: 0.2903  data_time: 0.0019  lr: 0.000739  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:03 d2.utils.events]: \u001b[0m eta: 1:10:01  iter: 759  total_loss: 0.454  loss_cls: 0.073  loss_box_reg: 0.160  loss_mask: 0.112  loss_rpn_cls: 0.007  loss_rpn_loc: 0.062  time: 0.2904  data_time: 0.0025  lr: 0.000759  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:09 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 779  total_loss: 0.435  loss_cls: 0.083  loss_box_reg: 0.166  loss_mask: 0.119  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 0.2904  data_time: 0.0014  lr: 0.000779  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:15 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 799  total_loss: 0.379  loss_cls: 0.069  loss_box_reg: 0.135  loss_mask: 0.109  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 0.2904  data_time: 0.0014  lr: 0.000799  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:21 d2.utils.events]: \u001b[0m eta: 1:09:43  iter: 819  total_loss: 0.432  loss_cls: 0.064  loss_box_reg: 0.135  loss_mask: 0.112  loss_rpn_cls: 0.013  loss_rpn_loc: 0.078  time: 0.2904  data_time: 0.0014  lr: 0.000819  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:27 d2.utils.events]: \u001b[0m eta: 1:09:37  iter: 839  total_loss: 0.419  loss_cls: 0.066  loss_box_reg: 0.131  loss_mask: 0.115  loss_rpn_cls: 0.009  loss_rpn_loc: 0.064  time: 0.2905  data_time: 0.0012  lr: 0.000839  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:33 d2.utils.events]: \u001b[0m eta: 1:09:33  iter: 859  total_loss: 0.490  loss_cls: 0.073  loss_box_reg: 0.160  loss_mask: 0.114  loss_rpn_cls: 0.011  loss_rpn_loc: 0.099  time: 0.2906  data_time: 0.0018  lr: 0.000859  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:39 d2.utils.events]: \u001b[0m eta: 1:09:27  iter: 879  total_loss: 0.409  loss_cls: 0.067  loss_box_reg: 0.137  loss_mask: 0.106  loss_rpn_cls: 0.010  loss_rpn_loc: 0.067  time: 0.2907  data_time: 0.0019  lr: 0.000879  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:45 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 899  total_loss: 0.360  loss_cls: 0.056  loss_box_reg: 0.112  loss_mask: 0.101  loss_rpn_cls: 0.015  loss_rpn_loc: 0.065  time: 0.2906  data_time: 0.0018  lr: 0.000899  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:50 d2.utils.events]: \u001b[0m eta: 1:09:16  iter: 919  total_loss: 0.319  loss_cls: 0.056  loss_box_reg: 0.103  loss_mask: 0.094  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 0.2907  data_time: 0.0021  lr: 0.000919  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:49:56 d2.utils.events]: \u001b[0m eta: 1:09:11  iter: 939  total_loss: 0.321  loss_cls: 0.052  loss_box_reg: 0.100  loss_mask: 0.099  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 0.2908  data_time: 0.0022  lr: 0.000939  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:02 d2.utils.events]: \u001b[0m eta: 1:09:06  iter: 959  total_loss: 0.326  loss_cls: 0.051  loss_box_reg: 0.115  loss_mask: 0.094  loss_rpn_cls: 0.006  loss_rpn_loc: 0.060  time: 0.2908  data_time: 0.0034  lr: 0.000959  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:08 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 979  total_loss: 0.309  loss_cls: 0.055  loss_box_reg: 0.100  loss_mask: 0.093  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 0.2910  data_time: 0.0041  lr: 0.000979  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:14 d2.utils.events]: \u001b[0m eta: 1:08:57  iter: 999  total_loss: 0.318  loss_cls: 0.045  loss_box_reg: 0.104  loss_mask: 0.099  loss_rpn_cls: 0.007  loss_rpn_loc: 0.056  time: 0.2910  data_time: 0.0018  lr: 0.000999  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:20 d2.utils.events]: \u001b[0m eta: 1:08:57  iter: 1019  total_loss: 0.306  loss_cls: 0.047  loss_box_reg: 0.107  loss_mask: 0.088  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 0.2911  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:26 d2.utils.events]: \u001b[0m eta: 1:08:53  iter: 1039  total_loss: 0.302  loss_cls: 0.049  loss_box_reg: 0.106  loss_mask: 0.092  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 0.2911  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:32 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 1059  total_loss: 0.311  loss_cls: 0.046  loss_box_reg: 0.114  loss_mask: 0.087  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 0.2911  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:38 d2.utils.events]: \u001b[0m eta: 1:08:48  iter: 1079  total_loss: 0.306  loss_cls: 0.046  loss_box_reg: 0.118  loss_mask: 0.089  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 0.2912  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:44 d2.utils.events]: \u001b[0m eta: 1:08:45  iter: 1099  total_loss: 0.325  loss_cls: 0.046  loss_box_reg: 0.094  loss_mask: 0.111  loss_rpn_cls: 0.006  loss_rpn_loc: 0.067  time: 0.2912  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:50 d2.utils.events]: \u001b[0m eta: 1:08:41  iter: 1119  total_loss: 0.345  loss_cls: 0.048  loss_box_reg: 0.094  loss_mask: 0.096  loss_rpn_cls: 0.009  loss_rpn_loc: 0.088  time: 0.2912  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:50:56 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 1139  total_loss: 0.268  loss_cls: 0.044  loss_box_reg: 0.082  loss_mask: 0.081  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 0.2915  data_time: 0.0055  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:02 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 1159  total_loss: 0.269  loss_cls: 0.043  loss_box_reg: 0.088  loss_mask: 0.079  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 0.2918  data_time: 0.0051  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:08 d2.utils.events]: \u001b[0m eta: 1:08:33  iter: 1179  total_loss: 0.298  loss_cls: 0.046  loss_box_reg: 0.096  loss_mask: 0.086  loss_rpn_cls: 0.005  loss_rpn_loc: 0.053  time: 0.2919  data_time: 0.0037  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:14 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 1199  total_loss: 0.290  loss_cls: 0.038  loss_box_reg: 0.080  loss_mask: 0.086  loss_rpn_cls: 0.006  loss_rpn_loc: 0.057  time: 0.2922  data_time: 0.0064  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:20 d2.utils.events]: \u001b[0m eta: 1:08:27  iter: 1219  total_loss: 0.246  loss_cls: 0.038  loss_box_reg: 0.080  loss_mask: 0.077  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 0.2922  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:26 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 1239  total_loss: 0.257  loss_cls: 0.043  loss_box_reg: 0.082  loss_mask: 0.076  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 0.2923  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:32 d2.utils.events]: \u001b[0m eta: 1:08:16  iter: 1259  total_loss: 0.256  loss_cls: 0.034  loss_box_reg: 0.080  loss_mask: 0.080  loss_rpn_cls: 0.006  loss_rpn_loc: 0.057  time: 0.2922  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:38 d2.utils.events]: \u001b[0m eta: 1:08:10  iter: 1279  total_loss: 0.299  loss_cls: 0.034  loss_box_reg: 0.093  loss_mask: 0.078  loss_rpn_cls: 0.006  loss_rpn_loc: 0.059  time: 0.2923  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:44 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 1299  total_loss: 0.256  loss_cls: 0.036  loss_box_reg: 0.080  loss_mask: 0.079  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 0.2924  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:50 d2.utils.events]: \u001b[0m eta: 1:07:59  iter: 1319  total_loss: 0.250  loss_cls: 0.038  loss_box_reg: 0.076  loss_mask: 0.080  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 0.2925  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:51:56 d2.utils.events]: \u001b[0m eta: 1:07:53  iter: 1339  total_loss: 0.281  loss_cls: 0.041  loss_box_reg: 0.087  loss_mask: 0.080  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 0.2926  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:52:02 d2.utils.events]: \u001b[0m eta: 1:07:48  iter: 1359  total_loss: 0.242  loss_cls: 0.039  loss_box_reg: 0.074  loss_mask: 0.073  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 0.2927  data_time: 0.0070  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:08 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 1379  total_loss: 0.270  loss_cls: 0.040  loss_box_reg: 0.079  loss_mask: 0.080  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 0.2928  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:14 d2.utils.events]: \u001b[0m eta: 1:07:42  iter: 1399  total_loss: 0.234  loss_cls: 0.040  loss_box_reg: 0.075  loss_mask: 0.075  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 0.2930  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:20 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 1419  total_loss: 0.244  loss_cls: 0.038  loss_box_reg: 0.078  loss_mask: 0.072  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 0.2932  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:26 d2.utils.events]: \u001b[0m eta: 1:07:31  iter: 1439  total_loss: 0.264  loss_cls: 0.038  loss_box_reg: 0.083  loss_mask: 0.073  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 0.2932  data_time: 0.0064  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:32 d2.utils.events]: \u001b[0m eta: 1:07:24  iter: 1459  total_loss: 0.241  loss_cls: 0.035  loss_box_reg: 0.069  loss_mask: 0.074  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 0.2932  data_time: 0.0065  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:38 d2.utils.events]: \u001b[0m eta: 1:07:19  iter: 1479  total_loss: 0.222  loss_cls: 0.037  loss_box_reg: 0.066  loss_mask: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 0.2933  data_time: 0.0063  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:44 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 1499  total_loss: 0.250  loss_cls: 0.041  loss_box_reg: 0.081  loss_mask: 0.070  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 0.2934  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:50 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 1519  total_loss: 0.261  loss_cls: 0.040  loss_box_reg: 0.076  loss_mask: 0.074  loss_rpn_cls: 0.005  loss_rpn_loc: 0.030  time: 0.2936  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:52:57 d2.utils.events]: \u001b[0m eta: 1:07:01  iter: 1539  total_loss: 0.221  loss_cls: 0.033  loss_box_reg: 0.075  loss_mask: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 0.2936  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:02 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 1559  total_loss: 0.237  loss_cls: 0.037  loss_box_reg: 0.068  loss_mask: 0.071  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 0.2936  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:08 d2.utils.events]: \u001b[0m eta: 1:06:47  iter: 1579  total_loss: 0.319  loss_cls: 0.035  loss_box_reg: 0.087  loss_mask: 0.083  loss_rpn_cls: 0.006  loss_rpn_loc: 0.061  time: 0.2935  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:14 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 1599  total_loss: 0.267  loss_cls: 0.041  loss_box_reg: 0.087  loss_mask: 0.075  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 0.2935  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:20 d2.utils.events]: \u001b[0m eta: 1:06:36  iter: 1619  total_loss: 0.224  loss_cls: 0.040  loss_box_reg: 0.073  loss_mask: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.032  time: 0.2936  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:26 d2.utils.events]: \u001b[0m eta: 1:06:32  iter: 1639  total_loss: 0.232  loss_cls: 0.037  loss_box_reg: 0.072  loss_mask: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 0.2937  data_time: 0.0049  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:32 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 1659  total_loss: 0.189  loss_cls: 0.032  loss_box_reg: 0.059  loss_mask: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2938  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:38 d2.utils.events]: \u001b[0m eta: 1:06:21  iter: 1679  total_loss: 0.216  loss_cls: 0.033  loss_box_reg: 0.082  loss_mask: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.032  time: 0.2939  data_time: 0.0041  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:44 d2.utils.events]: \u001b[0m eta: 1:06:13  iter: 1699  total_loss: 0.267  loss_cls: 0.028  loss_box_reg: 0.085  loss_mask: 0.076  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 0.2939  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:50 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 1719  total_loss: 0.227  loss_cls: 0.037  loss_box_reg: 0.071  loss_mask: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 0.2939  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:53:56 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 1739  total_loss: 0.261  loss_cls: 0.032  loss_box_reg: 0.068  loss_mask: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.063  time: 0.2939  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:02 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 1759  total_loss: 0.217  loss_cls: 0.029  loss_box_reg: 0.068  loss_mask: 0.067  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 0.2940  data_time: 0.0042  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:08 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 1779  total_loss: 0.184  loss_cls: 0.031  loss_box_reg: 0.061  loss_mask: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.027  time: 0.2940  data_time: 0.0043  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:14 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 1799  total_loss: 0.182  loss_cls: 0.028  loss_box_reg: 0.063  loss_mask: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 0.2941  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:20 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 1819  total_loss: 0.172  loss_cls: 0.029  loss_box_reg: 0.058  loss_mask: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2942  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:26 d2.utils.events]: \u001b[0m eta: 1:05:33  iter: 1839  total_loss: 0.208  loss_cls: 0.036  loss_box_reg: 0.068  loss_mask: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:32 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 1859  total_loss: 0.220  loss_cls: 0.033  loss_box_reg: 0.068  loss_mask: 0.064  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 0.2942  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:38 d2.utils.events]: \u001b[0m eta: 1:05:20  iter: 1879  total_loss: 0.242  loss_cls: 0.030  loss_box_reg: 0.065  loss_mask: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.059  time: 0.2941  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:44 d2.utils.events]: \u001b[0m eta: 1:05:13  iter: 1899  total_loss: 0.182  loss_cls: 0.030  loss_box_reg: 0.061  loss_mask: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:50 d2.utils.events]: \u001b[0m eta: 1:05:07  iter: 1919  total_loss: 0.210  loss_cls: 0.028  loss_box_reg: 0.073  loss_mask: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:54:56 d2.utils.events]: \u001b[0m eta: 1:05:01  iter: 1939  total_loss: 0.183  loss_cls: 0.031  loss_box_reg: 0.060  loss_mask: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:02 d2.utils.events]: \u001b[0m eta: 1:04:54  iter: 1959  total_loss: 0.219  loss_cls: 0.027  loss_box_reg: 0.070  loss_mask: 0.065  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:08 d2.utils.events]: \u001b[0m eta: 1:04:47  iter: 1979  total_loss: 0.210  loss_cls: 0.034  loss_box_reg: 0.060  loss_mask: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 0.2941  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:14 d2.utils.events]: \u001b[0m eta: 1:04:42  iter: 1999  total_loss: 0.194  loss_cls: 0.030  loss_box_reg: 0.060  loss_mask: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.028  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:55:19 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 2019  total_loss: 0.216  loss_cls: 0.028  loss_box_reg: 0.065  loss_mask: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:25 d2.utils.events]: \u001b[0m eta: 1:04:30  iter: 2039  total_loss: 0.205  loss_cls: 0.030  loss_box_reg: 0.066  loss_mask: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 0.2941  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:31 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 2059  total_loss: 0.265  loss_cls: 0.027  loss_box_reg: 0.077  loss_mask: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.059  time: 0.2940  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:37 d2.utils.events]: \u001b[0m eta: 1:04:17  iter: 2079  total_loss: 0.220  loss_cls: 0.033  loss_box_reg: 0.065  loss_mask: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 0.2940  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:43 d2.utils.events]: \u001b[0m eta: 1:04:11  iter: 2099  total_loss: 0.191  loss_cls: 0.033  loss_box_reg: 0.069  loss_mask: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.026  time: 0.2941  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:49 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 2119  total_loss: 0.182  loss_cls: 0.027  loss_box_reg: 0.053  loss_mask: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.029  time: 0.2941  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:55:55 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2139  total_loss: 0.192  loss_cls: 0.028  loss_box_reg: 0.055  loss_mask: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:01 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 2159  total_loss: 0.169  loss_cls: 0.027  loss_box_reg: 0.057  loss_mask: 0.056  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 0.2941  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:07 d2.utils.events]: \u001b[0m eta: 1:03:43  iter: 2179  total_loss: 0.184  loss_cls: 0.028  loss_box_reg: 0.064  loss_mask: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2941  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:13 d2.utils.events]: \u001b[0m eta: 1:03:39  iter: 2199  total_loss: 0.165  loss_cls: 0.027  loss_box_reg: 0.057  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2942  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:19 d2.utils.events]: \u001b[0m eta: 1:03:31  iter: 2219  total_loss: 0.185  loss_cls: 0.024  loss_box_reg: 0.059  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:25 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 2239  total_loss: 0.198  loss_cls: 0.027  loss_box_reg: 0.064  loss_mask: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 0.2942  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:31 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 2259  total_loss: 0.192  loss_cls: 0.029  loss_box_reg: 0.058  loss_mask: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 0.2943  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:37 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 2279  total_loss: 0.175  loss_cls: 0.028  loss_box_reg: 0.054  loss_mask: 0.055  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:43 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 2299  total_loss: 0.179  loss_cls: 0.031  loss_box_reg: 0.050  loss_mask: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.035  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:49 d2.utils.events]: \u001b[0m eta: 1:03:05  iter: 2319  total_loss: 0.179  loss_cls: 0.031  loss_box_reg: 0.057  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:56:55 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 2339  total_loss: 0.205  loss_cls: 0.027  loss_box_reg: 0.068  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 0.2943  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:01 d2.utils.events]: \u001b[0m eta: 1:02:50  iter: 2359  total_loss: 0.281  loss_cls: 0.030  loss_box_reg: 0.071  loss_mask: 0.067  loss_rpn_cls: 0.006  loss_rpn_loc: 0.083  time: 0.2943  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:07 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 2379  total_loss: 0.190  loss_cls: 0.026  loss_box_reg: 0.054  loss_mask: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 0.2943  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:13 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 2399  total_loss: 0.163  loss_cls: 0.028  loss_box_reg: 0.049  loss_mask: 0.054  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:19 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 2419  total_loss: 0.159  loss_cls: 0.025  loss_box_reg: 0.052  loss_mask: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:25 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 2439  total_loss: 0.166  loss_cls: 0.026  loss_box_reg: 0.053  loss_mask: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:31 d2.utils.events]: \u001b[0m eta: 1:02:16  iter: 2459  total_loss: 0.196  loss_cls: 0.032  loss_box_reg: 0.052  loss_mask: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:37 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 2479  total_loss: 0.171  loss_cls: 0.028  loss_box_reg: 0.054  loss_mask: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:43 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 2499  total_loss: 0.169  loss_cls: 0.026  loss_box_reg: 0.052  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:49 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 2519  total_loss: 0.204  loss_cls: 0.026  loss_box_reg: 0.056  loss_mask: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:57:55 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 2539  total_loss: 0.179  loss_cls: 0.031  loss_box_reg: 0.050  loss_mask: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:01 d2.utils.events]: \u001b[0m eta: 1:01:42  iter: 2559  total_loss: 0.164  loss_cls: 0.026  loss_box_reg: 0.051  loss_mask: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:07 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2579  total_loss: 0.181  loss_cls: 0.026  loss_box_reg: 0.057  loss_mask: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.031  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:13 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 2599  total_loss: 0.187  loss_cls: 0.028  loss_box_reg: 0.051  loss_mask: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.037  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:18 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 2619  total_loss: 0.230  loss_cls: 0.023  loss_box_reg: 0.070  loss_mask: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:24 d2.utils.events]: \u001b[0m eta: 1:01:18  iter: 2639  total_loss: 0.183  loss_cls: 0.027  loss_box_reg: 0.066  loss_mask: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:30 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 2659  total_loss: 0.180  loss_cls: 0.026  loss_box_reg: 0.069  loss_mask: 0.052  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 16:58:36 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 2679  total_loss: 0.263  loss_cls: 0.019  loss_box_reg: 0.053  loss_mask: 0.103  loss_rpn_cls: 0.005  loss_rpn_loc: 0.067  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:42 d2.utils.events]: \u001b[0m eta: 1:00:58  iter: 2699  total_loss: 0.173  loss_cls: 0.028  loss_box_reg: 0.048  loss_mask: 0.052  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2942  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:48 d2.utils.events]: \u001b[0m eta: 1:00:52  iter: 2719  total_loss: 0.180  loss_cls: 0.027  loss_box_reg: 0.053  loss_mask: 0.053  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 0.2942  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:58:54 d2.utils.events]: \u001b[0m eta: 1:00:46  iter: 2739  total_loss: 0.173  loss_cls: 0.022  loss_box_reg: 0.055  loss_mask: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:00 d2.utils.events]: \u001b[0m eta: 1:00:39  iter: 2759  total_loss: 0.167  loss_cls: 0.026  loss_box_reg: 0.050  loss_mask: 0.051  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2942  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:05 d2.utils.events]: \u001b[0m eta: 1:00:33  iter: 2779  total_loss: 0.222  loss_cls: 0.023  loss_box_reg: 0.056  loss_mask: 0.076  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:12 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 2799  total_loss: 0.174  loss_cls: 0.024  loss_box_reg: 0.055  loss_mask: 0.051  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 0.2942  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:18 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 2819  total_loss: 0.216  loss_cls: 0.027  loss_box_reg: 0.052  loss_mask: 0.074  loss_rpn_cls: 0.005  loss_rpn_loc: 0.058  time: 0.2941  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:24 d2.utils.events]: \u001b[0m eta: 1:00:15  iter: 2839  total_loss: 0.178  loss_cls: 0.026  loss_box_reg: 0.067  loss_mask: 0.051  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2942  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:30 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 2859  total_loss: 0.169  loss_cls: 0.027  loss_box_reg: 0.062  loss_mask: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 0.2943  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:36 d2.utils.events]: \u001b[0m eta: 1:00:04  iter: 2879  total_loss: 0.143  loss_cls: 0.026  loss_box_reg: 0.048  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:42 d2.utils.events]: \u001b[0m eta: 0:59:58  iter: 2899  total_loss: 0.179  loss_cls: 0.022  loss_box_reg: 0.050  loss_mask: 0.053  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:48 d2.utils.events]: \u001b[0m eta: 0:59:52  iter: 2919  total_loss: 0.145  loss_cls: 0.024  loss_box_reg: 0.046  loss_mask: 0.051  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 16:59:54 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 2939  total_loss: 0.146  loss_cls: 0.023  loss_box_reg: 0.046  loss_mask: 0.051  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2943  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:00 d2.utils.events]: \u001b[0m eta: 0:59:44  iter: 2959  total_loss: 0.172  loss_cls: 0.031  loss_box_reg: 0.048  loss_mask: 0.051  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 0.2944  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:06 d2.utils.events]: \u001b[0m eta: 0:59:39  iter: 2979  total_loss: 0.204  loss_cls: 0.027  loss_box_reg: 0.052  loss_mask: 0.054  loss_rpn_cls: 0.003  loss_rpn_loc: 0.051  time: 0.2945  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:12 d2.utils.events]: \u001b[0m eta: 0:59:33  iter: 2999  total_loss: 0.204  loss_cls: 0.028  loss_box_reg: 0.051  loss_mask: 0.054  loss_rpn_cls: 0.007  loss_rpn_loc: 0.060  time: 0.2945  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:18 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 3019  total_loss: 0.171  loss_cls: 0.021  loss_box_reg: 0.045  loss_mask: 0.051  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 0.2945  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:24 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 3039  total_loss: 0.210  loss_cls: 0.019  loss_box_reg: 0.058  loss_mask: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 0.2944  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:30 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 3059  total_loss: 0.172  loss_cls: 0.026  loss_box_reg: 0.058  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2944  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:36 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 3079  total_loss: 0.174  loss_cls: 0.023  loss_box_reg: 0.061  loss_mask: 0.050  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 0.2944  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:42 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 3099  total_loss: 0.168  loss_cls: 0.020  loss_box_reg: 0.058  loss_mask: 0.051  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 0.2945  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:48 d2.utils.events]: \u001b[0m eta: 0:59:01  iter: 3119  total_loss: 0.172  loss_cls: 0.023  loss_box_reg: 0.046  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 0.2945  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:00:54 d2.utils.events]: \u001b[0m eta: 0:58:55  iter: 3139  total_loss: 0.161  loss_cls: 0.027  loss_box_reg: 0.050  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2945  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:00 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 3159  total_loss: 0.151  loss_cls: 0.027  loss_box_reg: 0.045  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2945  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:06 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 3179  total_loss: 0.146  loss_cls: 0.022  loss_box_reg: 0.046  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:12 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 3199  total_loss: 0.155  loss_cls: 0.023  loss_box_reg: 0.048  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2946  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:18 d2.utils.events]: \u001b[0m eta: 0:58:31  iter: 3219  total_loss: 0.164  loss_cls: 0.024  loss_box_reg: 0.045  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:23 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 3239  total_loss: 0.179  loss_cls: 0.023  loss_box_reg: 0.056  loss_mask: 0.050  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 0.2945  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:29 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 3259  total_loss: 0.179  loss_cls: 0.024  loss_box_reg: 0.057  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 0.2946  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:35 d2.utils.events]: \u001b[0m eta: 0:58:12  iter: 3279  total_loss: 0.176  loss_cls: 0.024  loss_box_reg: 0.049  loss_mask: 0.051  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:41 d2.utils.events]: \u001b[0m eta: 0:58:06  iter: 3299  total_loss: 0.160  loss_cls: 0.023  loss_box_reg: 0.048  loss_mask: 0.052  loss_rpn_cls: 0.004  loss_rpn_loc: 0.031  time: 0.2946  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:47 d2.utils.events]: \u001b[0m eta: 0:57:59  iter: 3319  total_loss: 0.169  loss_cls: 0.025  loss_box_reg: 0.055  loss_mask: 0.052  loss_rpn_cls: 0.003  loss_rpn_loc: 0.031  time: 0.2946  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:01:53 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 3339  total_loss: 0.226  loss_cls: 0.019  loss_box_reg: 0.046  loss_mask: 0.071  loss_rpn_cls: 0.006  loss_rpn_loc: 0.070  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:01:59 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 3359  total_loss: 0.160  loss_cls: 0.020  loss_box_reg: 0.052  loss_mask: 0.048  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:05 d2.utils.events]: \u001b[0m eta: 0:57:42  iter: 3379  total_loss: 0.284  loss_cls: 0.023  loss_box_reg: 0.059  loss_mask: 0.098  loss_rpn_cls: 0.008  loss_rpn_loc: 0.081  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:11 d2.utils.events]: \u001b[0m eta: 0:57:37  iter: 3399  total_loss: 0.207  loss_cls: 0.028  loss_box_reg: 0.059  loss_mask: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:17 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 3419  total_loss: 0.171  loss_cls: 0.025  loss_box_reg: 0.051  loss_mask: 0.051  loss_rpn_cls: 0.005  loss_rpn_loc: 0.032  time: 0.2946  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:24 d2.utils.events]: \u001b[0m eta: 0:57:27  iter: 3439  total_loss: 0.153  loss_cls: 0.019  loss_box_reg: 0.047  loss_mask: 0.049  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 0.2947  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:30 d2.utils.events]: \u001b[0m eta: 0:57:23  iter: 3459  total_loss: 0.153  loss_cls: 0.020  loss_box_reg: 0.045  loss_mask: 0.051  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 0.2948  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:36 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 3479  total_loss: 0.208  loss_cls: 0.027  loss_box_reg: 0.055  loss_mask: 0.052  loss_rpn_cls: 0.003  loss_rpn_loc: 0.056  time: 0.2948  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:42 d2.utils.events]: \u001b[0m eta: 0:57:13  iter: 3499  total_loss: 0.175  loss_cls: 0.024  loss_box_reg: 0.045  loss_mask: 0.051  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 0.2949  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:48 d2.utils.events]: \u001b[0m eta: 0:57:10  iter: 3519  total_loss: 0.168  loss_cls: 0.020  loss_box_reg: 0.046  loss_mask: 0.054  loss_rpn_cls: 0.004  loss_rpn_loc: 0.031  time: 0.2949  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:02:54 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 3539  total_loss: 0.130  loss_cls: 0.023  loss_box_reg: 0.044  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.2949  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:00 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 3559  total_loss: 0.144  loss_cls: 0.022  loss_box_reg: 0.047  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2949  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:06 d2.utils.events]: \u001b[0m eta: 0:56:56  iter: 3579  total_loss: 0.166  loss_cls: 0.024  loss_box_reg: 0.054  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:12 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 3599  total_loss: 0.152  loss_cls: 0.023  loss_box_reg: 0.043  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2950  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:18 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 3619  total_loss: 0.145  loss_cls: 0.020  loss_box_reg: 0.045  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:24 d2.utils.events]: \u001b[0m eta: 0:56:42  iter: 3639  total_loss: 0.154  loss_cls: 0.023  loss_box_reg: 0.043  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.030  time: 0.2951  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:30 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 3659  total_loss: 0.149  loss_cls: 0.016  loss_box_reg: 0.042  loss_mask: 0.050  loss_rpn_cls: 0.004  loss_rpn_loc: 0.027  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:36 d2.utils.events]: \u001b[0m eta: 0:56:34  iter: 3679  total_loss: 0.155  loss_cls: 0.022  loss_box_reg: 0.049  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:42 d2.utils.events]: \u001b[0m eta: 0:56:30  iter: 3699  total_loss: 0.146  loss_cls: 0.020  loss_box_reg: 0.049  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:49 d2.utils.events]: \u001b[0m eta: 0:56:25  iter: 3719  total_loss: 0.154  loss_cls: 0.022  loss_box_reg: 0.049  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.031  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:03:54 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 3739  total_loss: 0.152  loss_cls: 0.021  loss_box_reg: 0.040  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:00 d2.utils.events]: \u001b[0m eta: 0:56:15  iter: 3759  total_loss: 0.144  loss_cls: 0.021  loss_box_reg: 0.042  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:06 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 3779  total_loss: 0.157  loss_cls: 0.018  loss_box_reg: 0.047  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:12 d2.utils.events]: \u001b[0m eta: 0:56:04  iter: 3799  total_loss: 0.143  loss_cls: 0.018  loss_box_reg: 0.047  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:18 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 3819  total_loss: 0.133  loss_cls: 0.022  loss_box_reg: 0.043  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:24 d2.utils.events]: \u001b[0m eta: 0:55:51  iter: 3839  total_loss: 0.171  loss_cls: 0.020  loss_box_reg: 0.044  loss_mask: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2952  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:30 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 3859  total_loss: 0.138  loss_cls: 0.021  loss_box_reg: 0.039  loss_mask: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:36 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 3879  total_loss: 0.154  loss_cls: 0.019  loss_box_reg: 0.040  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2952  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:42 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 3899  total_loss: 0.134  loss_cls: 0.018  loss_box_reg: 0.037  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2952  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:48 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 3919  total_loss: 0.147  loss_cls: 0.020  loss_box_reg: 0.043  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:04:54 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 3939  total_loss: 0.165  loss_cls: 0.026  loss_box_reg: 0.048  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.048  time: 0.2953  data_time: 0.0033  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:00 d2.utils.events]: \u001b[0m eta: 0:55:12  iter: 3959  total_loss: 0.186  loss_cls: 0.022  loss_box_reg: 0.045  loss_mask: 0.051  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:06 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3979  total_loss: 0.141  loss_cls: 0.020  loss_box_reg: 0.046  loss_mask: 0.047  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:05:12 d2.utils.events]: \u001b[0m eta: 0:55:00  iter: 3999  total_loss: 0.127  loss_cls: 0.019  loss_box_reg: 0.042  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:18 d2.utils.events]: \u001b[0m eta: 0:54:56  iter: 4019  total_loss: 0.132  loss_cls: 0.017  loss_box_reg: 0.040  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:24 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 4039  total_loss: 0.148  loss_cls: 0.018  loss_box_reg: 0.042  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:30 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 4059  total_loss: 0.170  loss_cls: 0.020  loss_box_reg: 0.045  loss_mask: 0.048  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:36 d2.utils.events]: \u001b[0m eta: 0:54:37  iter: 4079  total_loss: 0.206  loss_cls: 0.023  loss_box_reg: 0.057  loss_mask: 0.083  loss_rpn_cls: 0.008  loss_rpn_loc: 0.057  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:42 d2.utils.events]: \u001b[0m eta: 0:54:30  iter: 4099  total_loss: 0.145  loss_cls: 0.024  loss_box_reg: 0.047  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:48 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 4119  total_loss: 0.146  loss_cls: 0.019  loss_box_reg: 0.043  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:05:54 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 4139  total_loss: 0.134  loss_cls: 0.017  loss_box_reg: 0.040  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:00 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 4159  total_loss: 0.126  loss_cls: 0.018  loss_box_reg: 0.040  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:05 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 4179  total_loss: 0.137  loss_cls: 0.015  loss_box_reg: 0.043  loss_mask: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:11 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 4199  total_loss: 0.134  loss_cls: 0.013  loss_box_reg: 0.040  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:17 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 4219  total_loss: 0.169  loss_cls: 0.024  loss_box_reg: 0.051  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.035  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:23 d2.utils.events]: \u001b[0m eta: 0:53:46  iter: 4239  total_loss: 0.153  loss_cls: 0.021  loss_box_reg: 0.046  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:29 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 4259  total_loss: 0.138  loss_cls: 0.019  loss_box_reg: 0.043  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:35 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 4279  total_loss: 0.131  loss_cls: 0.015  loss_box_reg: 0.041  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:41 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 4299  total_loss: 0.170  loss_cls: 0.016  loss_box_reg: 0.045  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.030  time: 0.2952  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:47 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 4319  total_loss: 0.138  loss_cls: 0.015  loss_box_reg: 0.038  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2952  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:53 d2.utils.events]: \u001b[0m eta: 0:53:17  iter: 4339  total_loss: 0.131  loss_cls: 0.019  loss_box_reg: 0.045  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:06:59 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 4359  total_loss: 0.139  loss_cls: 0.017  loss_box_reg: 0.045  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:05 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 4379  total_loss: 0.122  loss_cls: 0.017  loss_box_reg: 0.039  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2953  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:11 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 4399  total_loss: 0.130  loss_cls: 0.018  loss_box_reg: 0.041  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2953  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:17 d2.utils.events]: \u001b[0m eta: 0:52:52  iter: 4419  total_loss: 0.131  loss_cls: 0.017  loss_box_reg: 0.041  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2953  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:23 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 4439  total_loss: 0.142  loss_cls: 0.021  loss_box_reg: 0.050  loss_mask: 0.045  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:29 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 4459  total_loss: 0.145  loss_cls: 0.022  loss_box_reg: 0.043  loss_mask: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2953  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:35 d2.utils.events]: \u001b[0m eta: 0:52:32  iter: 4479  total_loss: 0.126  loss_cls: 0.017  loss_box_reg: 0.037  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:41 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 4499  total_loss: 0.139  loss_cls: 0.015  loss_box_reg: 0.038  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.027  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:47 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 4519  total_loss: 0.145  loss_cls: 0.019  loss_box_reg: 0.045  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:53 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 4539  total_loss: 0.163  loss_cls: 0.016  loss_box_reg: 0.045  loss_mask: 0.049  loss_rpn_cls: 0.004  loss_rpn_loc: 0.032  time: 0.2953  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:07:59 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 4559  total_loss: 0.144  loss_cls: 0.019  loss_box_reg: 0.044  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2953  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:05 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 4579  total_loss: 0.156  loss_cls: 0.017  loss_box_reg: 0.040  loss_mask: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.045  time: 0.2952  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:11 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 4599  total_loss: 0.142  loss_cls: 0.019  loss_box_reg: 0.044  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:17 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 4619  total_loss: 0.139  loss_cls: 0.018  loss_box_reg: 0.036  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:23 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 4639  total_loss: 0.122  loss_cls: 0.017  loss_box_reg: 0.036  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.2953  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:08:29 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 4659  total_loss: 0.120  loss_cls: 0.018  loss_box_reg: 0.037  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2953  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:35 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 4679  total_loss: 0.149  loss_cls: 0.016  loss_box_reg: 0.038  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:40 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 4699  total_loss: 0.140  loss_cls: 0.017  loss_box_reg: 0.039  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:46 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 4719  total_loss: 0.191  loss_cls: 0.019  loss_box_reg: 0.040  loss_mask: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.061  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:52 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 4739  total_loss: 0.154  loss_cls: 0.015  loss_box_reg: 0.038  loss_mask: 0.048  loss_rpn_cls: 0.004  loss_rpn_loc: 0.031  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:08:58 d2.utils.events]: \u001b[0m eta: 0:50:55  iter: 4759  total_loss: 0.167  loss_cls: 0.018  loss_box_reg: 0.051  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.032  time: 0.2952  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:04 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 4779  total_loss: 0.151  loss_cls: 0.016  loss_box_reg: 0.053  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:10 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 4799  total_loss: 0.156  loss_cls: 0.016  loss_box_reg: 0.048  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.024  time: 0.2952  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:16 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 4819  total_loss: 0.151  loss_cls: 0.019  loss_box_reg: 0.048  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.030  time: 0.2952  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:22 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 4839  total_loss: 0.142  loss_cls: 0.017  loss_box_reg: 0.040  loss_mask: 0.047  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2952  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:28 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 4859  total_loss: 0.142  loss_cls: 0.022  loss_box_reg: 0.045  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:34 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 4879  total_loss: 0.125  loss_cls: 0.019  loss_box_reg: 0.045  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2952  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:40 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 4899  total_loss: 0.153  loss_cls: 0.020  loss_box_reg: 0.045  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:46 d2.utils.events]: \u001b[0m eta: 0:50:07  iter: 4919  total_loss: 0.117  loss_cls: 0.018  loss_box_reg: 0.038  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:52 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 4939  total_loss: 0.124  loss_cls: 0.022  loss_box_reg: 0.034  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:09:57 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 4959  total_loss: 0.143  loss_cls: 0.019  loss_box_reg: 0.037  loss_mask: 0.049  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2951  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:03 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 4979  total_loss: 0.161  loss_cls: 0.014  loss_box_reg: 0.038  loss_mask: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 0.2951  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:11 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 4999  total_loss: 0.123  loss_cls: 0.020  loss_box_reg: 0.035  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2951  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:17 d2.utils.events]: \u001b[0m eta: 0:49:33  iter: 5019  total_loss: 0.141  loss_cls: 0.013  loss_box_reg: 0.037  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2951  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:23 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 5039  total_loss: 0.143  loss_cls: 0.015  loss_box_reg: 0.037  loss_mask: 0.048  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2950  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:29 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 5059  total_loss: 0.132  loss_cls: 0.015  loss_box_reg: 0.037  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2950  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:35 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 5079  total_loss: 0.130  loss_cls: 0.017  loss_box_reg: 0.037  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:41 d2.utils.events]: \u001b[0m eta: 0:49:06  iter: 5099  total_loss: 0.147  loss_cls: 0.014  loss_box_reg: 0.039  loss_mask: 0.046  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 0.2950  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:47 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 5119  total_loss: 0.140  loss_cls: 0.020  loss_box_reg: 0.038  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2950  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:53 d2.utils.events]: \u001b[0m eta: 0:48:54  iter: 5139  total_loss: 0.130  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2950  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:10:59 d2.utils.events]: \u001b[0m eta: 0:48:49  iter: 5159  total_loss: 0.125  loss_cls: 0.015  loss_box_reg: 0.040  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2950  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:05 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 5179  total_loss: 0.131  loss_cls: 0.015  loss_box_reg: 0.039  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2950  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:11 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 5199  total_loss: 0.146  loss_cls: 0.017  loss_box_reg: 0.043  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2950  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:17 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 5219  total_loss: 0.152  loss_cls: 0.018  loss_box_reg: 0.047  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 0.2950  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:22 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 5239  total_loss: 0.154  loss_cls: 0.021  loss_box_reg: 0.045  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2950  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:28 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 5259  total_loss: 0.155  loss_cls: 0.017  loss_box_reg: 0.050  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:34 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 5279  total_loss: 0.186  loss_cls: 0.014  loss_box_reg: 0.049  loss_mask: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 0.2949  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:40 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 5299  total_loss: 0.135  loss_cls: 0.020  loss_box_reg: 0.043  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2949  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:11:46 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 5319  total_loss: 0.119  loss_cls: 0.018  loss_box_reg: 0.037  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:52 d2.utils.events]: \u001b[0m eta: 0:47:53  iter: 5339  total_loss: 0.116  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:11:58 d2.utils.events]: \u001b[0m eta: 0:47:45  iter: 5359  total_loss: 0.121  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2949  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:04 d2.utils.events]: \u001b[0m eta: 0:47:38  iter: 5379  total_loss: 0.121  loss_cls: 0.020  loss_box_reg: 0.034  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2949  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:10 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 5399  total_loss: 0.126  loss_cls: 0.019  loss_box_reg: 0.035  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2950  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:16 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 5419  total_loss: 0.135  loss_cls: 0.021  loss_box_reg: 0.041  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2950  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:22 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 5439  total_loss: 0.121  loss_cls: 0.016  loss_box_reg: 0.038  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.2950  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:28 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 5459  total_loss: 0.131  loss_cls: 0.017  loss_box_reg: 0.038  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:34 d2.utils.events]: \u001b[0m eta: 0:47:09  iter: 5479  total_loss: 0.142  loss_cls: 0.016  loss_box_reg: 0.034  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:40 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 5499  total_loss: 0.116  loss_cls: 0.016  loss_box_reg: 0.033  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2950  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:46 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 5519  total_loss: 0.116  loss_cls: 0.018  loss_box_reg: 0.035  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2950  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:52 d2.utils.events]: \u001b[0m eta: 0:46:53  iter: 5539  total_loss: 0.133  loss_cls: 0.015  loss_box_reg: 0.037  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.030  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:12:58 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 5559  total_loss: 0.128  loss_cls: 0.018  loss_box_reg: 0.041  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:04 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 5579  total_loss: 0.118  loss_cls: 0.018  loss_box_reg: 0.036  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2950  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:10 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 5599  total_loss: 0.115  loss_cls: 0.016  loss_box_reg: 0.034  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:16 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 5619  total_loss: 0.115  loss_cls: 0.013  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:22 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 5639  total_loss: 0.123  loss_cls: 0.020  loss_box_reg: 0.037  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2951  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:28 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 5659  total_loss: 0.114  loss_cls: 0.014  loss_box_reg: 0.033  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:34 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 5679  total_loss: 0.119  loss_cls: 0.018  loss_box_reg: 0.040  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:40 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 5699  total_loss: 0.159  loss_cls: 0.018  loss_box_reg: 0.036  loss_mask: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.030  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:46 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 5719  total_loss: 0.121  loss_cls: 0.017  loss_box_reg: 0.041  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2951  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:52 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 5739  total_loss: 0.126  loss_cls: 0.018  loss_box_reg: 0.037  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:13:58 d2.utils.events]: \u001b[0m eta: 0:45:52  iter: 5759  total_loss: 0.133  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:04 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 5779  total_loss: 0.113  loss_cls: 0.017  loss_box_reg: 0.034  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:10 d2.utils.events]: \u001b[0m eta: 0:45:40  iter: 5799  total_loss: 0.113  loss_cls: 0.014  loss_box_reg: 0.038  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:16 d2.utils.events]: \u001b[0m eta: 0:45:34  iter: 5819  total_loss: 0.119  loss_cls: 0.013  loss_box_reg: 0.035  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:22 d2.utils.events]: \u001b[0m eta: 0:45:30  iter: 5839  total_loss: 0.108  loss_cls: 0.013  loss_box_reg: 0.033  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:28 d2.utils.events]: \u001b[0m eta: 0:45:24  iter: 5859  total_loss: 0.135  loss_cls: 0.018  loss_box_reg: 0.037  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.034  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:34 d2.utils.events]: \u001b[0m eta: 0:45:18  iter: 5879  total_loss: 0.140  loss_cls: 0.020  loss_box_reg: 0.038  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:40 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 5899  total_loss: 0.132  loss_cls: 0.016  loss_box_reg: 0.043  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:46 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 5919  total_loss: 0.132  loss_cls: 0.016  loss_box_reg: 0.040  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:52 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 5939  total_loss: 0.106  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:14:58 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 5959  total_loss: 0.129  loss_cls: 0.016  loss_box_reg: 0.036  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:15:04 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 5979  total_loss: 0.129  loss_cls: 0.015  loss_box_reg: 0.037  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.030  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:09 d2.utils.events]: \u001b[0m eta: 0:44:44  iter: 5999  total_loss: 0.129  loss_cls: 0.016  loss_box_reg: 0.038  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:15 d2.utils.events]: \u001b[0m eta: 0:44:38  iter: 6019  total_loss: 0.126  loss_cls: 0.016  loss_box_reg: 0.039  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:21 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 6039  total_loss: 0.123  loss_cls: 0.012  loss_box_reg: 0.036  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:27 d2.utils.events]: \u001b[0m eta: 0:44:27  iter: 6059  total_loss: 0.119  loss_cls: 0.014  loss_box_reg: 0.035  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:33 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 6079  total_loss: 0.110  loss_cls: 0.016  loss_box_reg: 0.034  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:39 d2.utils.events]: \u001b[0m eta: 0:44:16  iter: 6099  total_loss: 0.137  loss_cls: 0.015  loss_box_reg: 0.035  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:45 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 6119  total_loss: 0.116  loss_cls: 0.013  loss_box_reg: 0.033  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:51 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 6139  total_loss: 0.118  loss_cls: 0.018  loss_box_reg: 0.032  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:15:57 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 6159  total_loss: 0.109  loss_cls: 0.016  loss_box_reg: 0.033  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:03 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 6179  total_loss: 0.114  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:09 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 6199  total_loss: 0.119  loss_cls: 0.016  loss_box_reg: 0.035  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:15 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 6219  total_loss: 0.152  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:21 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 6239  total_loss: 0.164  loss_cls: 0.018  loss_box_reg: 0.043  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:27 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 6259  total_loss: 0.157  loss_cls: 0.017  loss_box_reg: 0.038  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:33 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 6279  total_loss: 0.155  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.070  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:39 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 6299  total_loss: 0.125  loss_cls: 0.016  loss_box_reg: 0.037  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.024  time: 0.2951  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:45 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 6319  total_loss: 0.139  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:51 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 6339  total_loss: 0.131  loss_cls: 0.018  loss_box_reg: 0.041  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:16:56 d2.utils.events]: \u001b[0m eta: 0:42:59  iter: 6359  total_loss: 0.121  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:02 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 6379  total_loss: 0.122  loss_cls: 0.017  loss_box_reg: 0.033  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2951  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:08 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 6399  total_loss: 0.104  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:14 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 6419  total_loss: 0.106  loss_cls: 0.013  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:20 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 6439  total_loss: 0.117  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:26 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 6459  total_loss: 0.107  loss_cls: 0.016  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:32 d2.utils.events]: \u001b[0m eta: 0:42:23  iter: 6479  total_loss: 0.115  loss_cls: 0.017  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:38 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 6499  total_loss: 0.114  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2951  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:44 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 6519  total_loss: 0.118  loss_cls: 0.012  loss_box_reg: 0.034  loss_mask: 0.040  loss_rpn_cls: 0.001  loss_rpn_loc: 0.019  time: 0.2951  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:50 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 6539  total_loss: 0.144  loss_cls: 0.017  loss_box_reg: 0.047  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:17:56 d2.utils.events]: \u001b[0m eta: 0:41:58  iter: 6559  total_loss: 0.142  loss_cls: 0.014  loss_box_reg: 0.041  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:02 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 6579  total_loss: 0.176  loss_cls: 0.016  loss_box_reg: 0.039  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 0.2951  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:08 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 6599  total_loss: 0.128  loss_cls: 0.018  loss_box_reg: 0.039  loss_mask: 0.042  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:14 d2.utils.events]: \u001b[0m eta: 0:41:39  iter: 6619  total_loss: 0.138  loss_cls: 0.016  loss_box_reg: 0.032  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.037  time: 0.2951  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:18:20 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 6639  total_loss: 0.131  loss_cls: 0.017  loss_box_reg: 0.036  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.030  time: 0.2951  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:26 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 6659  total_loss: 0.121  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2951  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:32 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 6679  total_loss: 0.113  loss_cls: 0.013  loss_box_reg: 0.033  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2951  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:38 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 6699  total_loss: 0.116  loss_cls: 0.016  loss_box_reg: 0.034  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:43 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 6719  total_loss: 0.119  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2951  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:49 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 6739  total_loss: 0.112  loss_cls: 0.014  loss_box_reg: 0.033  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2951  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:18:56 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 6759  total_loss: 0.117  loss_cls: 0.016  loss_box_reg: 0.037  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:02 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 6779  total_loss: 0.108  loss_cls: 0.014  loss_box_reg: 0.033  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:08 d2.utils.events]: \u001b[0m eta: 0:40:44  iter: 6799  total_loss: 0.113  loss_cls: 0.014  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:13 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 6819  total_loss: 0.117  loss_cls: 0.013  loss_box_reg: 0.034  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2952  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:19 d2.utils.events]: \u001b[0m eta: 0:40:31  iter: 6839  total_loss: 0.133  loss_cls: 0.018  loss_box_reg: 0.035  loss_mask: 0.042  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2952  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:25 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 6859  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.030  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0032  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:31 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 6879  total_loss: 0.118  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:37 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 6899  total_loss: 0.124  loss_cls: 0.013  loss_box_reg: 0.030  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2952  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:43 d2.utils.events]: \u001b[0m eta: 0:40:06  iter: 6919  total_loss: 0.122  loss_cls: 0.017  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2952  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:49 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 6939  total_loss: 0.149  loss_cls: 0.016  loss_box_reg: 0.032  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 0.2951  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:19:55 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 6959  total_loss: 0.117  loss_cls: 0.012  loss_box_reg: 0.031  loss_mask: 0.042  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2951  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:01 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 6979  total_loss: 0.124  loss_cls: 0.016  loss_box_reg: 0.036  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2952  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:07 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 6999  total_loss: 0.113  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0062  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:14 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 7019  total_loss: 0.109  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2952  data_time: 0.0047  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:19 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 7039  total_loss: 0.118  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.043  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2952  data_time: 0.0041  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:25 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 7059  total_loss: 0.124  loss_cls: 0.013  loss_box_reg: 0.034  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.027  time: 0.2952  data_time: 0.0034  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:31 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 7079  total_loss: 0.128  loss_cls: 0.014  loss_box_reg: 0.040  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2952  data_time: 0.0030  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:37 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 7099  total_loss: 0.110  loss_cls: 0.013  loss_box_reg: 0.029  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2952  data_time: 0.0046  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:44 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 7119  total_loss: 0.113  loss_cls: 0.020  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2953  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:50 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 7139  total_loss: 0.104  loss_cls: 0.015  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2953  data_time: 0.0038  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:20:56 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 7159  total_loss: 0.095  loss_cls: 0.014  loss_box_reg: 0.029  loss_mask: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 0.2953  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:02 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 7179  total_loss: 0.101  loss_cls: 0.015  loss_box_reg: 0.027  loss_mask: 0.040  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 0.2953  data_time: 0.0038  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:08 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 7199  total_loss: 0.100  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0041  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:14 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 7219  total_loss: 0.147  loss_cls: 0.018  loss_box_reg: 0.038  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.036  time: 0.2954  data_time: 0.0038  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:20 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 7239  total_loss: 0.128  loss_cls: 0.018  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0061  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:26 d2.utils.events]: \u001b[0m eta: 0:38:37  iter: 7259  total_loss: 0.113  loss_cls: 0.017  loss_box_reg: 0.034  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:32 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 7279  total_loss: 0.119  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0049  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:21:38 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 7299  total_loss: 0.128  loss_cls: 0.017  loss_box_reg: 0.039  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:44 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 7319  total_loss: 0.137  loss_cls: 0.014  loss_box_reg: 0.034  loss_mask: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.028  time: 0.2954  data_time: 0.0035  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:50 d2.utils.events]: \u001b[0m eta: 0:38:14  iter: 7339  total_loss: 0.130  loss_cls: 0.014  loss_box_reg: 0.032  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.029  time: 0.2954  data_time: 0.0037  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:21:56 d2.utils.events]: \u001b[0m eta: 0:38:09  iter: 7359  total_loss: 0.135  loss_cls: 0.016  loss_box_reg: 0.042  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2955  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:02 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 7379  total_loss: 0.139  loss_cls: 0.015  loss_box_reg: 0.037  loss_mask: 0.042  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 0.2955  data_time: 0.0045  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:08 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 7399  total_loss: 0.115  loss_cls: 0.017  loss_box_reg: 0.033  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0049  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:14 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 7419  total_loss: 0.126  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2955  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:20 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 7439  total_loss: 0.125  loss_cls: 0.014  loss_box_reg: 0.028  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0031  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:26 d2.utils.events]: \u001b[0m eta: 0:37:40  iter: 7459  total_loss: 0.117  loss_cls: 0.014  loss_box_reg: 0.029  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2954  data_time: 0.0034  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:32 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 7479  total_loss: 0.126  loss_cls: 0.017  loss_box_reg: 0.035  loss_mask: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2954  data_time: 0.0033  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:38 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 7499  total_loss: 0.116  loss_cls: 0.018  loss_box_reg: 0.033  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2954  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:44 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 7519  total_loss: 0.114  loss_cls: 0.017  loss_box_reg: 0.032  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2954  data_time: 0.0044  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:50 d2.utils.events]: \u001b[0m eta: 0:37:18  iter: 7539  total_loss: 0.112  loss_cls: 0.016  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0057  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:22:56 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 7559  total_loss: 0.111  loss_cls: 0.014  loss_box_reg: 0.036  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0063  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:02 d2.utils.events]: \u001b[0m eta: 0:37:08  iter: 7579  total_loss: 0.110  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:08 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 7599  total_loss: 0.119  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.028  time: 0.2955  data_time: 0.0064  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:14 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 7619  total_loss: 0.124  loss_cls: 0.016  loss_box_reg: 0.030  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.030  time: 0.2955  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:20 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 7639  total_loss: 0.117  loss_cls: 0.017  loss_box_reg: 0.030  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0051  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:26 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 7659  total_loss: 0.118  loss_cls: 0.013  loss_box_reg: 0.029  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0035  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:32 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 7679  total_loss: 0.115  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2955  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:38 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 7699  total_loss: 0.115  loss_cls: 0.013  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0030  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:44 d2.utils.events]: \u001b[0m eta: 0:36:29  iter: 7719  total_loss: 0.116  loss_cls: 0.014  loss_box_reg: 0.033  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:50 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 7739  total_loss: 0.106  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:23:56 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 7759  total_loss: 0.111  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:02 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 7779  total_loss: 0.102  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:08 d2.utils.events]: \u001b[0m eta: 0:36:04  iter: 7799  total_loss: 0.112  loss_cls: 0.015  loss_box_reg: 0.028  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:13 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 7819  total_loss: 0.140  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:19 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 7839  total_loss: 0.132  loss_cls: 0.018  loss_box_reg: 0.036  loss_mask: 0.042  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:25 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 7859  total_loss: 0.107  loss_cls: 0.016  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:31 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 7879  total_loss: 0.115  loss_cls: 0.016  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0042  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:37 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 7899  total_loss: 0.112  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0037  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:43 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 7919  total_loss: 0.105  loss_cls: 0.016  loss_box_reg: 0.034  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:24:49 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 7939  total_loss: 0.119  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2955  data_time: 0.0040  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:24:55 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 7959  total_loss: 0.146  loss_cls: 0.010  loss_box_reg: 0.031  loss_mask: 0.043  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 0.2955  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:01 d2.utils.events]: \u001b[0m eta: 0:35:11  iter: 7979  total_loss: 0.146  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 0.2955  data_time: 0.0036  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:07 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 7999  total_loss: 0.101  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:13 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 8019  total_loss: 0.106  loss_cls: 0.015  loss_box_reg: 0.026  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0039  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:19 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 8039  total_loss: 0.100  loss_cls: 0.012  loss_box_reg: 0.027  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0037  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:25 d2.utils.events]: \u001b[0m eta: 0:34:46  iter: 8059  total_loss: 0.104  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0026  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:31 d2.utils.events]: \u001b[0m eta: 0:34:40  iter: 8079  total_loss: 0.145  loss_cls: 0.012  loss_box_reg: 0.033  loss_mask: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.035  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:37 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 8099  total_loss: 0.164  loss_cls: 0.013  loss_box_reg: 0.036  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.051  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:43 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 8119  total_loss: 0.113  loss_cls: 0.013  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:49 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 8139  total_loss: 0.114  loss_cls: 0.011  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:25:55 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 8159  total_loss: 0.114  loss_cls: 0.014  loss_box_reg: 0.036  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:01 d2.utils.events]: \u001b[0m eta: 0:34:08  iter: 8179  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:07 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 8199  total_loss: 0.101  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0041  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:13 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 8219  total_loss: 0.107  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0032  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:19 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 8239  total_loss: 0.123  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:25 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 8259  total_loss: 0.108  loss_cls: 0.015  loss_box_reg: 0.035  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:31 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 8279  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:37 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 8299  total_loss: 0.117  loss_cls: 0.016  loss_box_reg: 0.037  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:43 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 8319  total_loss: 0.104  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:48 d2.utils.events]: \u001b[0m eta: 0:33:15  iter: 8339  total_loss: 0.108  loss_cls: 0.011  loss_box_reg: 0.030  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:26:54 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 8359  total_loss: 0.141  loss_cls: 0.014  loss_box_reg: 0.035  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:00 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 8379  total_loss: 0.111  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:06 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 8399  total_loss: 0.111  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:12 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 8419  total_loss: 0.106  loss_cls: 0.015  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:18 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 8439  total_loss: 0.101  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:24 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 8459  total_loss: 0.102  loss_cls: 0.017  loss_box_reg: 0.028  loss_mask: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:30 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 8479  total_loss: 0.090  loss_cls: 0.015  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.2955  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:36 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 8499  total_loss: 0.112  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2955  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:42 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 8519  total_loss: 0.097  loss_cls: 0.015  loss_box_reg: 0.029  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:48 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 8539  total_loss: 0.108  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:27:54 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 8559  total_loss: 0.113  loss_cls: 0.011  loss_box_reg: 0.029  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2955  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:00 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 8579  total_loss: 0.118  loss_cls: 0.014  loss_box_reg: 0.039  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0026  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:06 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 8599  total_loss: 0.124  loss_cls: 0.013  loss_box_reg: 0.035  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:28:11 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 8619  total_loss: 0.121  loss_cls: 0.018  loss_box_reg: 0.035  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2955  data_time: 0.0035  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:18 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 8639  total_loss: 0.108  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0041  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:23 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 8659  total_loss: 0.123  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.041  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:29 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 8679  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:35 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 8699  total_loss: 0.117  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:41 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 8719  total_loss: 0.115  loss_cls: 0.016  loss_box_reg: 0.036  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:47 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 8739  total_loss: 0.108  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:53 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 8759  total_loss: 0.114  loss_cls: 0.016  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:28:59 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 8779  total_loss: 0.119  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:05 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 8799  total_loss: 0.120  loss_cls: 0.014  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:11 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 8819  total_loss: 0.106  loss_cls: 0.016  loss_box_reg: 0.026  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:17 d2.utils.events]: \u001b[0m eta: 0:30:38  iter: 8839  total_loss: 0.114  loss_cls: 0.016  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:23 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 8859  total_loss: 0.112  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2954  data_time: 0.0038  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:29 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 8879  total_loss: 0.117  loss_cls: 0.014  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0050  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:35 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 8899  total_loss: 0.099  loss_cls: 0.016  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:40 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 8919  total_loss: 0.098  loss_cls: 0.013  loss_box_reg: 0.025  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:46 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 8939  total_loss: 0.113  loss_cls: 0.012  loss_box_reg: 0.039  loss_mask: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0030  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:52 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 8959  total_loss: 0.125  loss_cls: 0.013  loss_box_reg: 0.037  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:29:58 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 8979  total_loss: 0.117  loss_cls: 0.011  loss_box_reg: 0.028  loss_mask: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:04 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 8999  total_loss: 0.115  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:11 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 9019  total_loss: 0.114  loss_cls: 0.013  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:16 d2.utils.events]: \u001b[0m eta: 0:29:38  iter: 9039  total_loss: 0.122  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0018  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:22 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 9059  total_loss: 0.124  loss_cls: 0.012  loss_box_reg: 0.048  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0032  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:28 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 9079  total_loss: 0.114  loss_cls: 0.011  loss_box_reg: 0.037  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0048  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:34 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 9099  total_loss: 0.098  loss_cls: 0.012  loss_box_reg: 0.028  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:41 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 9119  total_loss: 0.092  loss_cls: 0.015  loss_box_reg: 0.024  loss_mask: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:47 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 9139  total_loss: 0.110  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:53 d2.utils.events]: \u001b[0m eta: 0:29:03  iter: 9159  total_loss: 0.120  loss_cls: 0.013  loss_box_reg: 0.034  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:30:58 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 9179  total_loss: 0.128  loss_cls: 0.013  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.024  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:04 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 9199  total_loss: 0.144  loss_cls: 0.014  loss_box_reg: 0.035  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:10 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 9219  total_loss: 0.110  loss_cls: 0.010  loss_box_reg: 0.035  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:16 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 9239  total_loss: 0.105  loss_cls: 0.015  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:22 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 9259  total_loss: 0.111  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:31:28 d2.utils.events]: \u001b[0m eta: 0:28:26  iter: 9279  total_loss: 0.116  loss_cls: 0.012  loss_box_reg: 0.036  loss_mask: 0.038  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:34 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 9299  total_loss: 0.122  loss_cls: 0.011  loss_box_reg: 0.031  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:40 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 9319  total_loss: 0.127  loss_cls: 0.015  loss_box_reg: 0.041  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:46 d2.utils.events]: \u001b[0m eta: 0:28:08  iter: 9339  total_loss: 0.117  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:52 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 9359  total_loss: 0.110  loss_cls: 0.011  loss_box_reg: 0.032  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:31:58 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 9379  total_loss: 0.097  loss_cls: 0.012  loss_box_reg: 0.029  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:04 d2.utils.events]: \u001b[0m eta: 0:27:50  iter: 9399  total_loss: 0.105  loss_cls: 0.011  loss_box_reg: 0.030  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:09 d2.utils.events]: \u001b[0m eta: 0:27:44  iter: 9419  total_loss: 0.131  loss_cls: 0.013  loss_box_reg: 0.037  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:15 d2.utils.events]: \u001b[0m eta: 0:27:39  iter: 9439  total_loss: 0.111  loss_cls: 0.014  loss_box_reg: 0.038  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:21 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 9459  total_loss: 0.124  loss_cls: 0.010  loss_box_reg: 0.035  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:27 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 9479  total_loss: 0.099  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:33 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 9499  total_loss: 0.113  loss_cls: 0.013  loss_box_reg: 0.035  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:39 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 9519  total_loss: 0.127  loss_cls: 0.010  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:45 d2.utils.events]: \u001b[0m eta: 0:27:09  iter: 9539  total_loss: 0.123  loss_cls: 0.013  loss_box_reg: 0.036  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:51 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 9559  total_loss: 0.132  loss_cls: 0.009  loss_box_reg: 0.022  loss_mask: 0.066  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:32:57 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 9579  total_loss: 0.110  loss_cls: 0.015  loss_box_reg: 0.029  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:03 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 9599  total_loss: 0.125  loss_cls: 0.012  loss_box_reg: 0.031  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:09 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 9619  total_loss: 0.105  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:15 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 9639  total_loss: 0.103  loss_cls: 0.015  loss_box_reg: 0.031  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:21 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 9659  total_loss: 0.101  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:27 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 9679  total_loss: 0.116  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:33 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 9699  total_loss: 0.121  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:38 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 9719  total_loss: 0.113  loss_cls: 0.014  loss_box_reg: 0.024  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:44 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 9739  total_loss: 0.118  loss_cls: 0.015  loss_box_reg: 0.032  loss_mask: 0.040  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.2954  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:50 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 9759  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:33:56 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 9779  total_loss: 0.118  loss_cls: 0.011  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:02 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 9799  total_loss: 0.120  loss_cls: 0.012  loss_box_reg: 0.033  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:08 d2.utils.events]: \u001b[0m eta: 0:25:44  iter: 9819  total_loss: 0.128  loss_cls: 0.018  loss_box_reg: 0.036  loss_mask: 0.038  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:14 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 9839  total_loss: 0.111  loss_cls: 0.010  loss_box_reg: 0.029  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:19 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 9859  total_loss: 0.124  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:26 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 9879  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.029  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:32 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 9899  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.028  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:38 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 9919  total_loss: 0.110  loss_cls: 0.013  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:34:44 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 9939  total_loss: 0.119  loss_cls: 0.015  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:50 d2.utils.events]: \u001b[0m eta: 0:25:04  iter: 9959  total_loss: 0.131  loss_cls: 0.012  loss_box_reg: 0.028  loss_mask: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:34:56 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 9979  total_loss: 0.109  loss_cls: 0.013  loss_box_reg: 0.029  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:05 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 9999  total_loss: 0.101  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:11 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 10019  total_loss: 0.104  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.039  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:17 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 10039  total_loss: 0.111  loss_cls: 0.014  loss_box_reg: 0.028  loss_mask: 0.040  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:23 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 10059  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:29 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 10079  total_loss: 0.109  loss_cls: 0.010  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:35 d2.utils.events]: \u001b[0m eta: 0:24:22  iter: 10099  total_loss: 0.094  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:41 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 10119  total_loss: 0.107  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:47 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 10139  total_loss: 0.117  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.028  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:53 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 10159  total_loss: 0.118  loss_cls: 0.010  loss_box_reg: 0.030  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:35:59 d2.utils.events]: \u001b[0m eta: 0:23:56  iter: 10179  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:05 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 10199  total_loss: 0.113  loss_cls: 0.015  loss_box_reg: 0.034  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:11 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 10219  total_loss: 0.125  loss_cls: 0.011  loss_box_reg: 0.031  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.028  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:17 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 10239  total_loss: 0.102  loss_cls: 0.015  loss_box_reg: 0.028  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:23 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 10259  total_loss: 0.090  loss_cls: 0.013  loss_box_reg: 0.025  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2955  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:29 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 10279  total_loss: 0.115  loss_cls: 0.014  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.027  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:35 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 10299  total_loss: 0.109  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:41 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 10319  total_loss: 0.106  loss_cls: 0.014  loss_box_reg: 0.031  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:47 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 10339  total_loss: 0.109  loss_cls: 0.013  loss_box_reg: 0.032  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:53 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 10359  total_loss: 0.114  loss_cls: 0.015  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:36:59 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 10379  total_loss: 0.110  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:04 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 10399  total_loss: 0.115  loss_cls: 0.010  loss_box_reg: 0.030  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2955  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:10 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 10419  total_loss: 0.115  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2955  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:16 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 10439  total_loss: 0.092  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:22 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 10459  total_loss: 0.096  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:28 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 10479  total_loss: 0.117  loss_cls: 0.014  loss_box_reg: 0.030  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.027  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:34 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 10499  total_loss: 0.102  loss_cls: 0.014  loss_box_reg: 0.028  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:40 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 10519  total_loss: 0.099  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:46 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 10539  total_loss: 0.130  loss_cls: 0.011  loss_box_reg: 0.033  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:52 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 10559  total_loss: 0.102  loss_cls: 0.009  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:37:58 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 10579  total_loss: 0.099  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:38:04 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 10599  total_loss: 0.098  loss_cls: 0.011  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:10 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 10619  total_loss: 0.091  loss_cls: 0.013  loss_box_reg: 0.025  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:16 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 10639  total_loss: 0.088  loss_cls: 0.011  loss_box_reg: 0.021  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2955  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:22 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 10659  total_loss: 0.102  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:28 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 10679  total_loss: 0.115  loss_cls: 0.012  loss_box_reg: 0.026  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.031  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:34 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 10699  total_loss: 0.108  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:40 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 10719  total_loss: 0.102  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.038  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:45 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 10739  total_loss: 0.130  loss_cls: 0.012  loss_box_reg: 0.032  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:51 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 10759  total_loss: 0.104  loss_cls: 0.009  loss_box_reg: 0.033  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:38:57 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 10779  total_loss: 0.091  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.2955  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:03 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 10799  total_loss: 0.093  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:09 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 10819  total_loss: 0.100  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2954  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:15 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 10839  total_loss: 0.107  loss_cls: 0.013  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:21 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 10859  total_loss: 0.096  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:27 d2.utils.events]: \u001b[0m eta: 0:20:29  iter: 10879  total_loss: 0.102  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:33 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 10899  total_loss: 0.102  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:39 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 10919  total_loss: 0.110  loss_cls: 0.012  loss_box_reg: 0.026  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2955  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:45 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 10939  total_loss: 0.118  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.032  time: 0.2954  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:51 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 10959  total_loss: 0.105  loss_cls: 0.013  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:39:57 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 10979  total_loss: 0.100  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:03 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 10999  total_loss: 0.103  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2954  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:09 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 11019  total_loss: 0.108  loss_cls: 0.011  loss_box_reg: 0.032  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:15 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 11039  total_loss: 0.096  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0021  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:21 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 11059  total_loss: 0.090  loss_cls: 0.011  loss_box_reg: 0.022  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2955  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:26 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 11079  total_loss: 0.108  loss_cls: 0.013  loss_box_reg: 0.024  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:32 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 11099  total_loss: 0.104  loss_cls: 0.009  loss_box_reg: 0.023  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:38 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 11119  total_loss: 0.128  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.030  time: 0.2954  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:44 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 11139  total_loss: 0.109  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2954  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:50 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 11159  total_loss: 0.101  loss_cls: 0.013  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:40:56 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 11179  total_loss: 0.098  loss_cls: 0.016  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0030  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:02 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 11199  total_loss: 0.097  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:08 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 11219  total_loss: 0.129  loss_cls: 0.014  loss_box_reg: 0.030  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 0.2954  data_time: 0.0038  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:14 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 11239  total_loss: 0.105  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2954  data_time: 0.0031  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:41:20 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 11259  total_loss: 0.093  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0042  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:26 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 11279  total_loss: 0.096  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:32 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 11299  total_loss: 0.088  loss_cls: 0.010  loss_box_reg: 0.023  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0035  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:38 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 11319  total_loss: 0.095  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.017  time: 0.2954  data_time: 0.0026  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:44 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 11339  total_loss: 0.104  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2954  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:50 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 11359  total_loss: 0.100  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:41:56 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 11379  total_loss: 0.084  loss_cls: 0.009  loss_box_reg: 0.023  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.2954  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:02 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 11399  total_loss: 0.085  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2954  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:08 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 11419  total_loss: 0.097  loss_cls: 0.010  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2954  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:13 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 11439  total_loss: 0.104  loss_cls: 0.006  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:19 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 11459  total_loss: 0.112  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.039  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:25 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 11479  total_loss: 0.114  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:31 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 11499  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.036  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0018  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:37 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 11519  total_loss: 0.085  loss_cls: 0.010  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:43 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 11539  total_loss: 0.082  loss_cls: 0.010  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 0.2954  data_time: 0.0021  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:49 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 11559  total_loss: 0.089  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:42:56 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 11579  total_loss: 0.085  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 0.2954  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:02 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 11599  total_loss: 0.099  loss_cls: 0.011  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:07 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 11619  total_loss: 0.109  loss_cls: 0.011  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:13 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 11639  total_loss: 0.096  loss_cls: 0.010  loss_box_reg: 0.032  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.2954  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:19 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 11659  total_loss: 0.102  loss_cls: 0.010  loss_box_reg: 0.031  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:25 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 11679  total_loss: 0.095  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:31 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 11699  total_loss: 0.096  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:37 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 11719  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.029  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:43 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 11739  total_loss: 0.109  loss_cls: 0.010  loss_box_reg: 0.028  loss_mask: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0021  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:49 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 11759  total_loss: 0.097  loss_cls: 0.014  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:43:55 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 11779  total_loss: 0.101  loss_cls: 0.012  loss_box_reg: 0.023  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.023  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:01 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 11799  total_loss: 0.111  loss_cls: 0.012  loss_box_reg: 0.028  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:07 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 11819  total_loss: 0.103  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2954  data_time: 0.0013  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:13 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 11839  total_loss: 0.105  loss_cls: 0.015  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:19 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 11859  total_loss: 0.090  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:25 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 11879  total_loss: 0.095  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:31 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 11899  total_loss: 0.103  loss_cls: 0.013  loss_box_reg: 0.031  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:44:37 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 11919  total_loss: 0.094  loss_cls: 0.013  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:43 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 11939  total_loss: 0.092  loss_cls: 0.012  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:49 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 11959  total_loss: 0.112  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:44:55 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 11979  total_loss: 0.110  loss_cls: 0.014  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 0.2954  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:01 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 11999  total_loss: 0.106  loss_cls: 0.011  loss_box_reg: 0.028  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:07 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 12019  total_loss: 0.101  loss_cls: 0.017  loss_box_reg: 0.030  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:13 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 12039  total_loss: 0.107  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0018  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:19 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 12059  total_loss: 0.097  loss_cls: 0.013  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:25 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 12079  total_loss: 0.100  loss_cls: 0.017  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:31 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 12099  total_loss: 0.100  loss_cls: 0.015  loss_box_reg: 0.023  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:37 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 12119  total_loss: 0.082  loss_cls: 0.009  loss_box_reg: 0.022  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:42 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 12139  total_loss: 0.118  loss_cls: 0.006  loss_box_reg: 0.020  loss_mask: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:48 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 12159  total_loss: 0.092  loss_cls: 0.008  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:45:54 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 12179  total_loss: 0.099  loss_cls: 0.009  loss_box_reg: 0.027  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:00 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 12199  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.029  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:06 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 12219  total_loss: 0.094  loss_cls: 0.010  loss_box_reg: 0.022  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2954  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:12 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 12239  total_loss: 0.112  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:18 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 12259  total_loss: 0.091  loss_cls: 0.012  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:24 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 12279  total_loss: 0.088  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:30 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 12299  total_loss: 0.088  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:36 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 12319  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.023  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2954  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:42 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 12339  total_loss: 0.089  loss_cls: 0.008  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2954  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:48 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 12359  total_loss: 0.115  loss_cls: 0.008  loss_box_reg: 0.024  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.037  time: 0.2954  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:46:54 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 12379  total_loss: 0.119  loss_cls: 0.018  loss_box_reg: 0.032  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 0.2954  data_time: 0.0034  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:00 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 12399  total_loss: 0.106  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 0.2954  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:06 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 12419  total_loss: 0.084  loss_cls: 0.010  loss_box_reg: 0.023  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:12 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 12439  total_loss: 0.100  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0026  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:17 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 12459  total_loss: 0.110  loss_cls: 0.014  loss_box_reg: 0.030  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:23 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 12479  total_loss: 0.099  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2954  data_time: 0.0030  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:29 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 12499  total_loss: 0.085  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0023  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:35 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 12519  total_loss: 0.091  loss_cls: 0.012  loss_box_reg: 0.023  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0026  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:41 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 12539  total_loss: 0.085  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2954  data_time: 0.0021  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:47 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 12559  total_loss: 0.089  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:47:53 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 12579  total_loss: 0.090  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:47:59 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 12599  total_loss: 0.099  loss_cls: 0.008  loss_box_reg: 0.022  loss_mask: 0.046  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:05 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 12619  total_loss: 0.089  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0031  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:11 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 12639  total_loss: 0.106  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2954  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:16 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 12659  total_loss: 0.113  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.045  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2953  data_time: 0.0016  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:22 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 12679  total_loss: 0.108  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2953  data_time: 0.0019  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:28 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 12699  total_loss: 0.097  loss_cls: 0.010  loss_box_reg: 0.029  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2953  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:34 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 12719  total_loss: 0.079  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2953  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:40 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 12739  total_loss: 0.093  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.2953  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:46 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 12759  total_loss: 0.091  loss_cls: 0.013  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2953  data_time: 0.0011  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:52 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 12779  total_loss: 0.093  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2953  data_time: 0.0012  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:48:58 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 12799  total_loss: 0.099  loss_cls: 0.009  loss_box_reg: 0.023  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.024  time: 0.2953  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:04 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 12819  total_loss: 0.091  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:10 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 12839  total_loss: 0.108  loss_cls: 0.008  loss_box_reg: 0.024  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:16 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 12859  total_loss: 0.109  loss_cls: 0.006  loss_box_reg: 0.029  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:22 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 12879  total_loss: 0.110  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.028  time: 0.2953  data_time: 0.0010  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:28 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 12899  total_loss: 0.102  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:34 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 12919  total_loss: 0.093  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:40 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 12939  total_loss: 0.086  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.2953  data_time: 0.0018  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:46 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 12959  total_loss: 0.088  loss_cls: 0.009  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2953  data_time: 0.0031  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:52 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 12979  total_loss: 0.099  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2953  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:49:58 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 12999  total_loss: 0.091  loss_cls: 0.009  loss_box_reg: 0.022  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:04 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 13019  total_loss: 0.101  loss_cls: 0.008  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.026  time: 0.2954  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:10 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 13039  total_loss: 0.093  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2954  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:16 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 13059  total_loss: 0.101  loss_cls: 0.007  loss_box_reg: 0.023  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2954  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:22 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 13079  total_loss: 0.095  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2954  data_time: 0.0032  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:28 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 13099  total_loss: 0.090  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.037  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0042  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:33 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 13119  total_loss: 0.100  loss_cls: 0.011  loss_box_reg: 0.023  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.025  time: 0.2954  data_time: 0.0031  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:39 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 13139  total_loss: 0.112  loss_cls: 0.008  loss_box_reg: 0.022  loss_mask: 0.045  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.2953  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:45 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 13159  total_loss: 0.098  loss_cls: 0.012  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2953  data_time: 0.0024  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:51 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 13179  total_loss: 0.104  loss_cls: 0.008  loss_box_reg: 0.024  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2953  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:50:57 d2.utils.events]: \u001b[0m eta: 0:08:55  iter: 13199  total_loss: 0.098  loss_cls: 0.007  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2953  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:03 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 13219  total_loss: 0.090  loss_cls: 0.012  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2953  data_time: 0.0037  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:51:09 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 13239  total_loss: 0.092  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.2953  data_time: 0.0034  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:14 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 13259  total_loss: 0.090  loss_cls: 0.008  loss_box_reg: 0.021  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2953  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:20 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 13279  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2953  data_time: 0.0020  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:26 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 13299  total_loss: 0.102  loss_cls: 0.010  loss_box_reg: 0.032  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2953  data_time: 0.0028  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:32 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 13319  total_loss: 0.104  loss_cls: 0.011  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2953  data_time: 0.0027  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:38 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 13339  total_loss: 0.100  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2953  data_time: 0.0029  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:44 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 13359  total_loss: 0.086  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2953  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:50 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 13379  total_loss: 0.092  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:51:56 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 13399  total_loss: 0.103  loss_cls: 0.016  loss_box_reg: 0.030  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2953  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:02 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 13419  total_loss: 0.087  loss_cls: 0.012  loss_box_reg: 0.028  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2953  data_time: 0.0015  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:08 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 13439  total_loss: 0.085  loss_cls: 0.011  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2953  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:14 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 13459  total_loss: 0.098  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2953  data_time: 0.0017  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:20 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 13479  total_loss: 0.118  loss_cls: 0.008  loss_box_reg: 0.034  loss_mask: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2953  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:25 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 13499  total_loss: 0.128  loss_cls: 0.012  loss_box_reg: 0.043  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2953  data_time: 0.0018  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:31 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 13519  total_loss: 0.116  loss_cls: 0.010  loss_box_reg: 0.044  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2953  data_time: 0.0022  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:38 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 13539  total_loss: 0.097  loss_cls: 0.013  loss_box_reg: 0.029  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2953  data_time: 0.0025  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:44 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 13559  total_loss: 0.091  loss_cls: 0.014  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2953  data_time: 0.0055  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:50 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 13579  total_loss: 0.104  loss_cls: 0.013  loss_box_reg: 0.030  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2953  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:52:56 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 13599  total_loss: 0.090  loss_cls: 0.013  loss_box_reg: 0.026  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2953  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:02 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 13619  total_loss: 0.093  loss_cls: 0.014  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2953  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:08 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 13639  total_loss: 0.095  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2953  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:14 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 13659  total_loss: 0.112  loss_cls: 0.014  loss_box_reg: 0.024  loss_mask: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.028  time: 0.2953  data_time: 0.0056  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:21 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 13679  total_loss: 0.093  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2953  data_time: 0.0065  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:27 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 13699  total_loss: 0.099  loss_cls: 0.008  loss_box_reg: 0.026  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:33 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 13719  total_loss: 0.095  loss_cls: 0.010  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2954  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:40 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 13739  total_loss: 0.086  loss_cls: 0.009  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0065  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:49 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 13759  total_loss: 0.083  loss_cls: 0.010  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:53:55 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 13779  total_loss: 0.088  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.2954  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:02 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 13799  total_loss: 0.114  loss_cls: 0.009  loss_box_reg: 0.043  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0070  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:08 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 13819  total_loss: 0.107  loss_cls: 0.007  loss_box_reg: 0.028  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2954  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:15 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 13839  total_loss: 0.089  loss_cls: 0.011  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2954  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:21 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 13859  total_loss: 0.095  loss_cls: 0.012  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2954  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:30 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 13879  total_loss: 0.087  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2954  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:54:37 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 13899  total_loss: 0.096  loss_cls: 0.008  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.2955  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:43 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 13919  total_loss: 0.101  loss_cls: 0.009  loss_box_reg: 0.028  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2955  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:49 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 13939  total_loss: 0.108  loss_cls: 0.009  loss_box_reg: 0.029  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:54:56 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 13959  total_loss: 0.111  loss_cls: 0.008  loss_box_reg: 0.030  loss_mask: 0.035  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.2955  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:02 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 13979  total_loss: 0.114  loss_cls: 0.010  loss_box_reg: 0.031  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2955  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:14 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 13999  total_loss: 0.103  loss_cls: 0.010  loss_box_reg: 0.036  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:20 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 14019  total_loss: 0.108  loss_cls: 0.011  loss_box_reg: 0.033  loss_mask: 0.036  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2955  data_time: 0.0055  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:27 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 14039  total_loss: 0.090  loss_cls: 0.008  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2955  data_time: 0.0068  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:33 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 14059  total_loss: 0.099  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 0.2955  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:40 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 14079  total_loss: 0.110  loss_cls: 0.009  loss_box_reg: 0.028  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2955  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:47 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 14099  total_loss: 0.089  loss_cls: 0.010  loss_box_reg: 0.025  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2956  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:55:53 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 14119  total_loss: 0.104  loss_cls: 0.010  loss_box_reg: 0.027  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2956  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:02 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 14139  total_loss: 0.087  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2956  data_time: 0.0069  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:13 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 14159  total_loss: 0.096  loss_cls: 0.009  loss_box_reg: 0.030  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2956  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:20 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 14179  total_loss: 0.095  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2956  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:26 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 14199  total_loss: 0.087  loss_cls: 0.010  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.2956  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:33 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 14219  total_loss: 0.092  loss_cls: 0.010  loss_box_reg: 0.021  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.2956  data_time: 0.0007  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:39 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 14239  total_loss: 0.091  loss_cls: 0.011  loss_box_reg: 0.024  loss_mask: 0.033  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2956  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:46 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 14259  total_loss: 0.108  loss_cls: 0.009  loss_box_reg: 0.028  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2957  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:52 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 14279  total_loss: 0.099  loss_cls: 0.009  loss_box_reg: 0.022  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 0.2957  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:56:59 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 14299  total_loss: 0.092  loss_cls: 0.008  loss_box_reg: 0.027  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2957  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:05 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 14319  total_loss: 0.076  loss_cls: 0.011  loss_box_reg: 0.021  loss_mask: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.2957  data_time: 0.0009  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:12 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 14339  total_loss: 0.089  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2957  data_time: 0.0008  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:18 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 14359  total_loss: 0.092  loss_cls: 0.009  loss_box_reg: 0.021  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2957  data_time: 0.0014  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:25 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 14379  total_loss: 0.093  loss_cls: 0.014  loss_box_reg: 0.025  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2957  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:32 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 14399  total_loss: 0.087  loss_cls: 0.010  loss_box_reg: 0.022  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2957  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:38 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 14419  total_loss: 0.083  loss_cls: 0.010  loss_box_reg: 0.022  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.2957  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:44 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 14439  total_loss: 0.082  loss_cls: 0.010  loss_box_reg: 0.021  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.2957  data_time: 0.0065  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:51 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 14459  total_loss: 0.080  loss_cls: 0.009  loss_box_reg: 0.025  loss_mask: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 0.2957  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:57:58 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 14479  total_loss: 0.084  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.2957  data_time: 0.0067  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:04 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 14499  total_loss: 0.094  loss_cls: 0.009  loss_box_reg: 0.026  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.2957  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:11 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 14519  total_loss: 0.100  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.020  time: 0.2957  data_time: 0.0064  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:17 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 14539  total_loss: 0.100  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.022  time: 0.2957  data_time: 0.0064  lr: 0.001000  max_mem: 1072M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 17:58:23 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 14559  total_loss: 0.099  loss_cls: 0.010  loss_box_reg: 0.026  loss_mask: 0.033  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 0.2957  data_time: 0.0057  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:30 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 14579  total_loss: 0.074  loss_cls: 0.007  loss_box_reg: 0.020  loss_mask: 0.033  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.2957  data_time: 0.0056  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:36 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 14599  total_loss: 0.079  loss_cls: 0.009  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.2958  data_time: 0.0057  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:43 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 14619  total_loss: 0.099  loss_cls: 0.005  loss_box_reg: 0.020  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2958  data_time: 0.0058  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:49 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 14639  total_loss: 0.090  loss_cls: 0.008  loss_box_reg: 0.022  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2958  data_time: 0.0055  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:58:55 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 14659  total_loss: 0.096  loss_cls: 0.009  loss_box_reg: 0.024  loss_mask: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.023  time: 0.2958  data_time: 0.0056  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:01 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 14679  total_loss: 0.087  loss_cls: 0.013  loss_box_reg: 0.023  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2958  data_time: 0.0055  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:08 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 14699  total_loss: 0.116  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.029  time: 0.2958  data_time: 0.0061  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:14 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 14719  total_loss: 0.094  loss_cls: 0.011  loss_box_reg: 0.027  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.2958  data_time: 0.0062  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:20 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 14739  total_loss: 0.092  loss_cls: 0.012  loss_box_reg: 0.022  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2958  data_time: 0.0053  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:27 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 14759  total_loss: 0.088  loss_cls: 0.012  loss_box_reg: 0.022  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2958  data_time: 0.0065  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:33 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 14779  total_loss: 0.119  loss_cls: 0.009  loss_box_reg: 0.027  loss_mask: 0.038  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 0.2958  data_time: 0.0066  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:39 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 14799  total_loss: 0.108  loss_cls: 0.012  loss_box_reg: 0.030  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 0.2958  data_time: 0.0062  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:45 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 14819  total_loss: 0.103  loss_cls: 0.012  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 0.2958  data_time: 0.0059  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:51 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 14839  total_loss: 0.090  loss_cls: 0.010  loss_box_reg: 0.021  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.2958  data_time: 0.0057  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 17:59:57 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 14859  total_loss: 0.094  loss_cls: 0.010  loss_box_reg: 0.023  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2958  data_time: 0.0054  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:04 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 14879  total_loss: 0.086  loss_cls: 0.012  loss_box_reg: 0.022  loss_mask: 0.034  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.2958  data_time: 0.0060  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:10 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 14899  total_loss: 0.074  loss_cls: 0.009  loss_box_reg: 0.019  loss_mask: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.2958  data_time: 0.0047  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:16 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 14919  total_loss: 0.078  loss_cls: 0.008  loss_box_reg: 0.023  loss_mask: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.2958  data_time: 0.0054  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:22 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 14939  total_loss: 0.113  loss_cls: 0.011  loss_box_reg: 0.026  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.032  time: 0.2958  data_time: 0.0050  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:28 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 14959  total_loss: 0.116  loss_cls: 0.015  loss_box_reg: 0.030  loss_mask: 0.036  loss_rpn_cls: 0.002  loss_rpn_loc: 0.027  time: 0.2958  data_time: 0.0053  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:00:35 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 14979  total_loss: 0.091  loss_cls: 0.011  loss_box_reg: 0.025  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.2958  data_time: 0.0050  lr: 0.001000  max_mem: 1072M\n",
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 800/800 [00:01<00:00, 535.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4003/4003 [00:08<00:00, 498.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: reading imageJ ROIs\n",
      "Total number of ROIs are: 10\n",
      "step 2: loading video in h5 format\n",
      "All keys; \n",
      "         GroupHierarchy.Groups.Datasets\n",
      "step 3: transfering video to images\n",
      "start saving images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 800/800 [00:01<00:00, 581.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: creating annotation dictionary\n",
      "step 5: converting to COCO style dataset\n",
      "start to write COCO style dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4003/4003 [00:06<00:00, 597.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 18:01:19 d2.data.common]: \u001b[0mSerializing 8000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 18:01:19 d2.data.common]: \u001b[0mSerialized dataset takes 33.11 MiB\n",
      "\u001b[32m[10/12 18:01:19 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(125,), max_size=1333, sample_style='choice')]\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 18:01:19 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/12 18:01:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 14999  total_loss: 0.098  loss_cls: 0.010  loss_box_reg: 0.021  loss_mask: 0.035  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.2958  data_time: 0.0045  lr: 0.001000  max_mem: 1072M\n",
      "\u001b[32m[10/12 18:01:19 d2.engine.hooks]: \u001b[0mOverall training speed: 14997 iterations in 1:13:57 (0.2959 s / it)\n",
      "\u001b[32m[10/12 18:01:19 d2.engine.hooks]: \u001b[0mTotal training time: 1:15:58 (0:02:01 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3ee34",
   "metadata": {},
   "source": [
    "#### Custom data loader (with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883814fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        dataloader = build_detection_train_loader(cfg,\n",
    "           mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "               T.Resize((800, 800)), \n",
    "               T.RandomBrightness(intensity_min=0.5, intensity_max=2), \n",
    "               T.RandomContrast(intensity_min=0.5, intensity_max=2), \n",
    "               T.RandomCrop(crop_type=\"relative\", crop_size=(0.8, 0.8)), \n",
    "               T.RandomFlip()\n",
    "               ]))\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aab6e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:11:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:11:31 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [Resize(shape=(800, 800)), RandomBrightness(intensity_min=0.5, intensity_max=2), RandomContrast(intensity_min=0.5, intensity_max=2), RandomCrop(crop_type='relative', crop_size=(0.8, 0.8)), RandomFlip()]\n",
      "\u001b[32m[10/25 13:11:35 d2.data.datasets.coco]: \u001b[0mLoading I:/Sina/Medical report segmentation/publaynet/val.json takes 3.64 seconds.\n",
      "\u001b[32m[10/25 13:11:35 d2.data.datasets.coco]: \u001b[0mLoaded 11245 images in COCO format from I:/Sina/Medical report segmentation/publaynet/val.json\n",
      "\u001b[32m[10/25 13:11:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 11245 images left.\n",
      "\u001b[32m[10/25 13:11:36 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    text    | 88625        |   title    | 18801        |    list    | 4239         |\n",
      "|   table    | 4769         |   figure   | 4327         |            |              |\n",
      "|   total    | 120761       |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:11:36 d2.data.common]: \u001b[0mSerializing 11245 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:11:37 d2.data.common]: \u001b[0mSerialized dataset takes 55.68 MiB\n",
      "\u001b[32m[10/25 13:11:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:11:38 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\detectron2-windows\\detectron2\\layers\\wrappers.py:226: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  return x.nonzero().unbind(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:12:03 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 19  total_loss: 6.839  loss_cls: 1.788  loss_box_reg: 0.283  loss_mask: 0.681  loss_rpn_cls: 3.534  loss_rpn_loc: 0.525  time: 0.2895  data_time: 0.3947  lr: 0.000020  max_mem: 1202M\n",
      "\u001b[32m[10/25 13:12:09 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 39  total_loss: 2.618  loss_cls: 1.180  loss_box_reg: 0.260  loss_mask: 0.662  loss_rpn_cls: 0.222  loss_rpn_loc: 0.450  time: 0.2868  data_time: 0.0013  lr: 0.000040  max_mem: 1217M\n",
      "\u001b[32m[10/25 13:12:15 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 59  total_loss: 1.928  loss_cls: 0.413  loss_box_reg: 0.232  loss_mask: 0.617  loss_rpn_cls: 0.236  loss_rpn_loc: 0.384  time: 0.2872  data_time: 0.0011  lr: 0.000060  max_mem: 1217M\n",
      "\u001b[32m[10/25 13:12:21 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 79  total_loss: 1.999  loss_cls: 0.474  loss_box_reg: 0.355  loss_mask: 0.560  loss_rpn_cls: 0.175  loss_rpn_loc: 0.444  time: 0.2876  data_time: 0.0011  lr: 0.000080  max_mem: 1221M\n",
      "\u001b[32m[10/25 13:12:27 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 99  total_loss: 2.020  loss_cls: 0.457  loss_box_reg: 0.403  loss_mask: 0.510  loss_rpn_cls: 0.147  loss_rpn_loc: 0.465  time: 0.2888  data_time: 0.0010  lr: 0.000100  max_mem: 1221M\n",
      "\u001b[32m[10/25 13:12:33 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 119  total_loss: 1.940  loss_cls: 0.477  loss_box_reg: 0.498  loss_mask: 0.455  loss_rpn_cls: 0.129  loss_rpn_loc: 0.380  time: 0.2908  data_time: 0.0010  lr: 0.000120  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:12:39 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 139  total_loss: 2.017  loss_cls: 0.465  loss_box_reg: 0.533  loss_mask: 0.428  loss_rpn_cls: 0.110  loss_rpn_loc: 0.379  time: 0.2937  data_time: 0.0011  lr: 0.000140  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:12:46 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 159  total_loss: 2.036  loss_cls: 0.471  loss_box_reg: 0.618  loss_mask: 0.416  loss_rpn_cls: 0.111  loss_rpn_loc: 0.319  time: 0.2959  data_time: 0.0010  lr: 0.000160  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:12:52 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 179  total_loss: 1.990  loss_cls: 0.424  loss_box_reg: 0.589  loss_mask: 0.390  loss_rpn_cls: 0.086  loss_rpn_loc: 0.399  time: 0.2983  data_time: 0.0010  lr: 0.000180  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:12:58 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 199  total_loss: 1.619  loss_cls: 0.398  loss_box_reg: 0.462  loss_mask: 0.361  loss_rpn_cls: 0.100  loss_rpn_loc: 0.343  time: 0.2989  data_time: 0.0010  lr: 0.000200  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:05 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 219  total_loss: 1.773  loss_cls: 0.399  loss_box_reg: 0.576  loss_mask: 0.294  loss_rpn_cls: 0.082  loss_rpn_loc: 0.344  time: 0.2997  data_time: 0.0010  lr: 0.000220  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:11 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 239  total_loss: 1.620  loss_cls: 0.371  loss_box_reg: 0.486  loss_mask: 0.288  loss_rpn_cls: 0.073  loss_rpn_loc: 0.308  time: 0.3002  data_time: 0.0011  lr: 0.000240  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:17 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 259  total_loss: 1.601  loss_cls: 0.346  loss_box_reg: 0.482  loss_mask: 0.253  loss_rpn_cls: 0.073  loss_rpn_loc: 0.387  time: 0.3011  data_time: 0.0011  lr: 0.000260  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:24 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 279  total_loss: 1.591  loss_cls: 0.393  loss_box_reg: 0.500  loss_mask: 0.240  loss_rpn_cls: 0.082  loss_rpn_loc: 0.359  time: 0.3021  data_time: 0.0010  lr: 0.000280  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:30 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 299  total_loss: 1.393  loss_cls: 0.309  loss_box_reg: 0.357  loss_mask: 0.229  loss_rpn_cls: 0.066  loss_rpn_loc: 0.319  time: 0.3022  data_time: 0.0011  lr: 0.000300  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:36 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 319  total_loss: 1.396  loss_cls: 0.306  loss_box_reg: 0.388  loss_mask: 0.203  loss_rpn_cls: 0.067  loss_rpn_loc: 0.339  time: 0.3026  data_time: 0.0010  lr: 0.000320  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:42 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 339  total_loss: 1.367  loss_cls: 0.326  loss_box_reg: 0.386  loss_mask: 0.228  loss_rpn_cls: 0.090  loss_rpn_loc: 0.318  time: 0.3032  data_time: 0.0010  lr: 0.000340  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:49 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 359  total_loss: 1.268  loss_cls: 0.274  loss_box_reg: 0.319  loss_mask: 0.176  loss_rpn_cls: 0.124  loss_rpn_loc: 0.350  time: 0.3035  data_time: 0.0010  lr: 0.000360  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:13:55 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 379  total_loss: 1.332  loss_cls: 0.287  loss_box_reg: 0.352  loss_mask: 0.187  loss_rpn_cls: 0.123  loss_rpn_loc: 0.351  time: 0.3037  data_time: 0.0010  lr: 0.000380  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:01 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 399  total_loss: 1.166  loss_cls: 0.231  loss_box_reg: 0.258  loss_mask: 0.171  loss_rpn_cls: 0.065  loss_rpn_loc: 0.308  time: 0.3036  data_time: 0.0010  lr: 0.000400  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:07 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 419  total_loss: 1.224  loss_cls: 0.241  loss_box_reg: 0.304  loss_mask: 0.173  loss_rpn_cls: 0.096  loss_rpn_loc: 0.322  time: 0.3042  data_time: 0.0011  lr: 0.000420  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:13 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 439  total_loss: 1.108  loss_cls: 0.218  loss_box_reg: 0.250  loss_mask: 0.164  loss_rpn_cls: 0.094  loss_rpn_loc: 0.374  time: 0.3041  data_time: 0.0010  lr: 0.000440  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:20 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 459  total_loss: 1.081  loss_cls: 0.235  loss_box_reg: 0.252  loss_mask: 0.138  loss_rpn_cls: 0.094  loss_rpn_loc: 0.281  time: 0.3043  data_time: 0.0010  lr: 0.000460  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:26 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 479  total_loss: 1.103  loss_cls: 0.244  loss_box_reg: 0.290  loss_mask: 0.143  loss_rpn_cls: 0.085  loss_rpn_loc: 0.305  time: 0.3046  data_time: 0.0010  lr: 0.000480  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:32 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 499  total_loss: 1.018  loss_cls: 0.186  loss_box_reg: 0.283  loss_mask: 0.162  loss_rpn_cls: 0.062  loss_rpn_loc: 0.321  time: 0.3049  data_time: 0.0010  lr: 0.000500  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:38 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 519  total_loss: 1.150  loss_cls: 0.230  loss_box_reg: 0.250  loss_mask: 0.172  loss_rpn_cls: 0.067  loss_rpn_loc: 0.362  time: 0.3053  data_time: 0.0010  lr: 0.000519  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:45 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 539  total_loss: 1.084  loss_cls: 0.204  loss_box_reg: 0.255  loss_mask: 0.127  loss_rpn_cls: 0.099  loss_rpn_loc: 0.358  time: 0.3056  data_time: 0.0011  lr: 0.000539  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:51 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 559  total_loss: 0.999  loss_cls: 0.227  loss_box_reg: 0.280  loss_mask: 0.142  loss_rpn_cls: 0.077  loss_rpn_loc: 0.284  time: 0.3060  data_time: 0.0010  lr: 0.000559  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:14:57 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 579  total_loss: 0.995  loss_cls: 0.217  loss_box_reg: 0.282  loss_mask: 0.110  loss_rpn_cls: 0.056  loss_rpn_loc: 0.320  time: 0.3062  data_time: 0.0010  lr: 0.000579  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:04 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 599  total_loss: 1.030  loss_cls: 0.215  loss_box_reg: 0.296  loss_mask: 0.132  loss_rpn_cls: 0.056  loss_rpn_loc: 0.302  time: 0.3064  data_time: 0.0010  lr: 0.000599  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:10 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 619  total_loss: 0.885  loss_cls: 0.162  loss_box_reg: 0.194  loss_mask: 0.112  loss_rpn_cls: 0.084  loss_rpn_loc: 0.313  time: 0.3063  data_time: 0.0010  lr: 0.000619  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:16 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 639  total_loss: 1.023  loss_cls: 0.213  loss_box_reg: 0.264  loss_mask: 0.135  loss_rpn_cls: 0.068  loss_rpn_loc: 0.331  time: 0.3065  data_time: 0.0010  lr: 0.000639  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:22 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 659  total_loss: 1.043  loss_cls: 0.177  loss_box_reg: 0.235  loss_mask: 0.131  loss_rpn_cls: 0.067  loss_rpn_loc: 0.334  time: 0.3065  data_time: 0.0010  lr: 0.000659  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:29 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 679  total_loss: 1.015  loss_cls: 0.206  loss_box_reg: 0.259  loss_mask: 0.129  loss_rpn_cls: 0.069  loss_rpn_loc: 0.293  time: 0.3068  data_time: 0.0010  lr: 0.000679  max_mem: 1383M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:15:35 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 699  total_loss: 0.889  loss_cls: 0.208  loss_box_reg: 0.272  loss_mask: 0.125  loss_rpn_cls: 0.076  loss_rpn_loc: 0.293  time: 0.3071  data_time: 0.0010  lr: 0.000699  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:41 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 719  total_loss: 0.995  loss_cls: 0.219  loss_box_reg: 0.244  loss_mask: 0.138  loss_rpn_cls: 0.060  loss_rpn_loc: 0.315  time: 0.3072  data_time: 0.0010  lr: 0.000719  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:48 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 739  total_loss: 0.991  loss_cls: 0.227  loss_box_reg: 0.262  loss_mask: 0.129  loss_rpn_cls: 0.079  loss_rpn_loc: 0.235  time: 0.3075  data_time: 0.0011  lr: 0.000739  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:15:54 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 759  total_loss: 1.040  loss_cls: 0.221  loss_box_reg: 0.247  loss_mask: 0.122  loss_rpn_cls: 0.083  loss_rpn_loc: 0.366  time: 0.3077  data_time: 0.0010  lr: 0.000759  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:00 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 779  total_loss: 0.801  loss_cls: 0.160  loss_box_reg: 0.197  loss_mask: 0.099  loss_rpn_cls: 0.050  loss_rpn_loc: 0.241  time: 0.3079  data_time: 0.0010  lr: 0.000779  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:07 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 799  total_loss: 1.028  loss_cls: 0.197  loss_box_reg: 0.256  loss_mask: 0.121  loss_rpn_cls: 0.075  loss_rpn_loc: 0.319  time: 0.3081  data_time: 0.0010  lr: 0.000799  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:13 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 819  total_loss: 0.960  loss_cls: 0.191  loss_box_reg: 0.236  loss_mask: 0.110  loss_rpn_cls: 0.075  loss_rpn_loc: 0.300  time: 0.3083  data_time: 0.0010  lr: 0.000819  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:20 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 839  total_loss: 1.048  loss_cls: 0.223  loss_box_reg: 0.251  loss_mask: 0.104  loss_rpn_cls: 0.066  loss_rpn_loc: 0.328  time: 0.3088  data_time: 0.0010  lr: 0.000839  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:26 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 859  total_loss: 0.866  loss_cls: 0.173  loss_box_reg: 0.232  loss_mask: 0.092  loss_rpn_cls: 0.057  loss_rpn_loc: 0.367  time: 0.3091  data_time: 0.0010  lr: 0.000859  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:33 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 879  total_loss: 1.091  loss_cls: 0.270  loss_box_reg: 0.261  loss_mask: 0.117  loss_rpn_cls: 0.102  loss_rpn_loc: 0.328  time: 0.3093  data_time: 0.0010  lr: 0.000879  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:39 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 899  total_loss: 0.764  loss_cls: 0.154  loss_box_reg: 0.192  loss_mask: 0.103  loss_rpn_cls: 0.073  loss_rpn_loc: 0.291  time: 0.3094  data_time: 0.0010  lr: 0.000899  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:45 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 919  total_loss: 0.947  loss_cls: 0.166  loss_box_reg: 0.208  loss_mask: 0.111  loss_rpn_cls: 0.069  loss_rpn_loc: 0.394  time: 0.3096  data_time: 0.0010  lr: 0.000919  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:52 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 939  total_loss: 1.031  loss_cls: 0.154  loss_box_reg: 0.262  loss_mask: 0.110  loss_rpn_cls: 0.063  loss_rpn_loc: 0.394  time: 0.3098  data_time: 0.0010  lr: 0.000939  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:16:58 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 959  total_loss: 0.886  loss_cls: 0.161  loss_box_reg: 0.229  loss_mask: 0.096  loss_rpn_cls: 0.062  loss_rpn_loc: 0.339  time: 0.3100  data_time: 0.0010  lr: 0.000959  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:05 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 979  total_loss: 0.859  loss_cls: 0.145  loss_box_reg: 0.205  loss_mask: 0.109  loss_rpn_cls: 0.050  loss_rpn_loc: 0.314  time: 0.3101  data_time: 0.0010  lr: 0.000979  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:11 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 999  total_loss: 0.957  loss_cls: 0.188  loss_box_reg: 0.222  loss_mask: 0.107  loss_rpn_cls: 0.065  loss_rpn_loc: 0.355  time: 0.3103  data_time: 0.0010  lr: 0.000999  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:17 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 1019  total_loss: 0.847  loss_cls: 0.158  loss_box_reg: 0.233  loss_mask: 0.099  loss_rpn_cls: 0.052  loss_rpn_loc: 0.310  time: 0.3103  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:24 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 1039  total_loss: 0.911  loss_cls: 0.171  loss_box_reg: 0.221  loss_mask: 0.111  loss_rpn_cls: 0.060  loss_rpn_loc: 0.349  time: 0.3105  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:30 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1059  total_loss: 0.926  loss_cls: 0.186  loss_box_reg: 0.247  loss_mask: 0.102  loss_rpn_cls: 0.067  loss_rpn_loc: 0.343  time: 0.3106  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:36 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1079  total_loss: 0.890  loss_cls: 0.200  loss_box_reg: 0.237  loss_mask: 0.116  loss_rpn_cls: 0.049  loss_rpn_loc: 0.302  time: 0.3107  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:43 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1099  total_loss: 0.834  loss_cls: 0.155  loss_box_reg: 0.179  loss_mask: 0.094  loss_rpn_cls: 0.064  loss_rpn_loc: 0.309  time: 0.3107  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:49 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 1119  total_loss: 0.866  loss_cls: 0.152  loss_box_reg: 0.201  loss_mask: 0.138  loss_rpn_cls: 0.059  loss_rpn_loc: 0.284  time: 0.3107  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:17:55 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 1139  total_loss: 0.723  loss_cls: 0.154  loss_box_reg: 0.203  loss_mask: 0.100  loss_rpn_cls: 0.035  loss_rpn_loc: 0.219  time: 0.3109  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:02 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 1159  total_loss: 0.857  loss_cls: 0.174  loss_box_reg: 0.221  loss_mask: 0.089  loss_rpn_cls: 0.068  loss_rpn_loc: 0.267  time: 0.3110  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:08 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 1179  total_loss: 0.973  loss_cls: 0.185  loss_box_reg: 0.222  loss_mask: 0.117  loss_rpn_cls: 0.050  loss_rpn_loc: 0.303  time: 0.3111  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:15 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 1199  total_loss: 0.811  loss_cls: 0.152  loss_box_reg: 0.186  loss_mask: 0.103  loss_rpn_cls: 0.068  loss_rpn_loc: 0.272  time: 0.3112  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:21 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1219  total_loss: 0.847  loss_cls: 0.143  loss_box_reg: 0.193  loss_mask: 0.114  loss_rpn_cls: 0.064  loss_rpn_loc: 0.247  time: 0.3113  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:27 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 1239  total_loss: 0.832  loss_cls: 0.149  loss_box_reg: 0.209  loss_mask: 0.090  loss_rpn_cls: 0.047  loss_rpn_loc: 0.316  time: 0.3114  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:34 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 1259  total_loss: 0.895  loss_cls: 0.143  loss_box_reg: 0.207  loss_mask: 0.097  loss_rpn_cls: 0.045  loss_rpn_loc: 0.321  time: 0.3115  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:40 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1279  total_loss: 0.826  loss_cls: 0.147  loss_box_reg: 0.212  loss_mask: 0.097  loss_rpn_cls: 0.073  loss_rpn_loc: 0.267  time: 0.3116  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:47 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1299  total_loss: 1.011  loss_cls: 0.182  loss_box_reg: 0.228  loss_mask: 0.104  loss_rpn_cls: 0.059  loss_rpn_loc: 0.355  time: 0.3118  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:53 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 1319  total_loss: 0.862  loss_cls: 0.172  loss_box_reg: 0.235  loss_mask: 0.104  loss_rpn_cls: 0.058  loss_rpn_loc: 0.296  time: 0.3120  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:18:59 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 1339  total_loss: 0.792  loss_cls: 0.146  loss_box_reg: 0.202  loss_mask: 0.110  loss_rpn_cls: 0.056  loss_rpn_loc: 0.289  time: 0.3120  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:19:06 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 1359  total_loss: 0.839  loss_cls: 0.137  loss_box_reg: 0.180  loss_mask: 0.097  loss_rpn_cls: 0.052  loss_rpn_loc: 0.326  time: 0.3121  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:12 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1379  total_loss: 0.848  loss_cls: 0.177  loss_box_reg: 0.227  loss_mask: 0.112  loss_rpn_cls: 0.063  loss_rpn_loc: 0.286  time: 0.3121  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:19 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 1399  total_loss: 0.808  loss_cls: 0.167  loss_box_reg: 0.174  loss_mask: 0.091  loss_rpn_cls: 0.044  loss_rpn_loc: 0.252  time: 0.3122  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:25 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 1419  total_loss: 0.621  loss_cls: 0.109  loss_box_reg: 0.142  loss_mask: 0.094  loss_rpn_cls: 0.049  loss_rpn_loc: 0.229  time: 0.3121  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:31 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1439  total_loss: 0.843  loss_cls: 0.136  loss_box_reg: 0.227  loss_mask: 0.118  loss_rpn_cls: 0.058  loss_rpn_loc: 0.240  time: 0.3122  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:38 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 1459  total_loss: 0.828  loss_cls: 0.168  loss_box_reg: 0.194  loss_mask: 0.115  loss_rpn_cls: 0.055  loss_rpn_loc: 0.251  time: 0.3122  data_time: 0.0010  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:44 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 1479  total_loss: 0.757  loss_cls: 0.124  loss_box_reg: 0.149  loss_mask: 0.087  loss_rpn_cls: 0.045  loss_rpn_loc: 0.314  time: 0.3123  data_time: 0.0014  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:56 d2.data.datasets.coco]: \u001b[0mLoading I:/Sina/Medical report segmentation/publaynet/val.json takes 3.54 seconds.\n",
      "\u001b[32m[10/25 13:19:56 d2.data.datasets.coco]: \u001b[0mLoaded 11245 images in COCO format from I:/Sina/Medical report segmentation/publaynet/val.json\n",
      "\u001b[32m[10/25 13:19:58 d2.data.common]: \u001b[0mSerializing 11245 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:19:58 d2.data.common]: \u001b[0mSerialized dataset takes 55.68 MiB\n",
      "\u001b[32m[10/25 13:19:58 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(125, 125), max_size=1333, sample_style='choice')]\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/25 13:19:58 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/25 13:19:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.877  loss_cls: 0.156  loss_box_reg: 0.198  loss_mask: 0.106  loss_rpn_cls: 0.049  loss_rpn_loc: 0.325  time: 0.3123  data_time: 0.0011  lr: 0.001000  max_mem: 1383M\n",
      "\u001b[32m[10/25 13:19:59 d2.engine.hooks]: \u001b[0mOverall training speed: 1497 iterations in 0:07:47 (0.3125 s / it)\n",
      "\u001b[32m[10/25 13:19:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:00 (0:00:12 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/dhiiyaur/detectron-2-compare-models-augmentation\n",
    "# first time install shapely\n",
    "\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48c7d9",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799750ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data frame!\n"
     ]
    }
   ],
   "source": [
    "# on single image\n",
    "\n",
    "# save result's image\n",
    "save_img = True\n",
    "\n",
    "# get dir path to image\n",
    "img_path = \"C:/Users/admin/Desktop/test/50.png\"\n",
    "\n",
    "# model weights (after training)\n",
    "model_weights_path = \"C:/Users/admin/Desktop/test/out2/model_final.pth\"\n",
    "\n",
    "# path for saving final results\n",
    "save_path = \"C:/Users/admin/Desktop/test/test\"\n",
    "\n",
    "# get configuration file same as used during training\n",
    "\n",
    "cfg = configuration(num_classes=1,\n",
    "                    train_output_path=\"C:/Users/admin/Desktop/test/out2\",\n",
    "                    min_image_size=125,\n",
    "                    image_per_batch=1,\n",
    "                    max_iter=150,\n",
    "                    model_weights=model_weights_path,\n",
    "                    validation=True)\n",
    "\n",
    "# initialize main dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "df = predict_img(cfg=cfg, img_path=img_path, save_path=save_path,\n",
    "                   img_save=save_img, df_save=False, score_thresh=0.8)\n",
    "\n",
    "# save main dataframe\n",
    "print(\"saving data frame!\")\n",
    "df.to_csv(os.path.join(save_path, \"main_results\") + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17613d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\detectron2\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 180.0 seconds\n",
      "saving data frame!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\detectron2\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# on multiple images\n",
    "\n",
    "# save result's image\n",
    "save_img = False\n",
    "\n",
    "# get dir path to images\n",
    "imgs_path = \"C:/Users/admin/Desktop/test/test_images\"\n",
    "\n",
    "# get images info\n",
    "imgs = os.listdir(imgs_path)\n",
    "\n",
    "# model weights (after training)\n",
    "model_weights_path = \"C:/Users/admin/Desktop/test/out2/model_final.pth\"\n",
    "\n",
    "# path for saving final results\n",
    "save_path = \"C:/Users/admin/Desktop/test/test\"\n",
    "\n",
    "# get configuration file same as used during training\n",
    "cfg = configuration(num_classes=1,\n",
    "                    train_output_path=\"C:/Users/admin/Desktop/test/out2\",\n",
    "                    min_image_size=125,\n",
    "                    image_per_batch=1,\n",
    "                    max_iter=150,\n",
    "                    model_weights=model_weights_path,\n",
    "                    validation=True)\n",
    "\n",
    "# initialize main dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# claculate time\n",
    "start_time = time.clock()\n",
    "\n",
    "# starting looping results\n",
    "for img in imgs:\n",
    "    df = df.append(predict_img(cfg=cfg, img_path=os.path.join(imgs_path, img), save_path=save_path,\n",
    "                               img_save=save_img, df_save=False, score_thresh=0.7), ignore_index=True)\n",
    "\n",
    "print(f'execution time: {np.rint(time.clock() - start_time)} seconds')\n",
    "\n",
    "# save main dataframe\n",
    "print(\"saving data frame!\")\n",
    "df.to_csv(os.path.join(save_path, \"main_results\") + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6268014b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
